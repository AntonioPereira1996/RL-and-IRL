#+TITLE: Calcul exact de la /feature expectation/
* Dynamic programming computation of $\mu$ header
** Détails techniques
   Python :
   #+begin_src python
from DP_mu import *

mu = DP_mu( pi, Psi )
   #+end_src
** Calcul de $\mu(s)$
*** Entrées
    - =pi= : Matrice de taille $|S|\times |S|$ représentant la politique
    - =Psi= : Matrice de taille $|S| \times p$ représentant les features sur l'espace d'état
*** Sorties
    - Matrice de taille $|S|\times p$ représentant $\mu^\pi(s)$
** Calcul de $\mu(s,a)$
*** Entrées
    - =pi= : Matrice de taille $|S|\times |S|$ représentant les probabilités de transition si l'on suit l'action $a$
    - =Psi= : Matrice de taille $|S| \times p$ représentant les features sur l'expace d'état
*** Sorties
    - Matrice de taille $|S|\times p$ repésentant $\mu^\pi(.,a)$
* Principe
  FIXME: dans l'explication, on a phi à la place de psi.
De la même manière qu'il est possible d'écrire l'equation de Bellman sous forme matricielle : 
\begin{equation}
V^\pi = R + \gamma P_\pi V^\pi 
\end{equation}
On peut écrire le même type d'équation pour $\mu$, pour une composante $i$ :
\begin{equation}
\mu^\pi_i = \phi_i + \gamma P_\pi\mu^\pi_i 
\end{equation}
Si l'on considère la matrice $\mathbf \mu$ comme étant indexée par les états sur les lignes et par les composantes sur les colonnes, et la même technique pour la matrice $\mathbf \Phi$, alors il est possible d'écrire : 
\begin{equation}
\mathbf \mu^\pi = \mathbf\Phi + \gamma P_\pi\mathbf\mu^\pi
\end{equation}
Grâce à cette équation il est possible d'adapter les algorithmes de programmation dynamique itératifs pour obtenir un calcul exact de $\mathbf \mu^\pi$.

Cependant, la fonction dont nous avons besoin n'est pas $\mu^\pi : S \rightarrow \mathbb R^p$, mais $\mu^\pi : S \times A \rightarrow \mathbb R^p$ (la notation reste la même pour ne pas tout surcharger, la différence étant réglée assze vite). Ces deux fonctions ont entre elles la même relation qu'ont $V$ et $Q$.
Ainsi puisque l'on peut écrire :
\begin{eqnarray}
Q^\pi(s,a) &=& R(s) + \gamma P_a(s)V^\pi\\
Q^\pi_a &=& R + \gamma P_aV^\pi
\end{eqnarray}
On peut faire le parallèle (en notant $\mu^\pi(s,\cdot) = \mu^\pi_a(s)$) :
\begin{eqnarray}
\mu^\pi(s,a) &=& \phi(s) + \gamma P_a(s)\mathbf \mu^\pi\\
\mathbf \mu^\pi_a &=& \mathbf \Phi + \gamma P_a\mathbf \mu^\pi
\end{eqnarray}

Pour résumer, il est possible de calculer la matrice $\mathbf \mu^\pi$ grâce à une adaptation des algorithmes de programmation dynamique, et à partir de celle ci de déduire les matrices $\mu^\pi_a$, qui sont celles dont nous avons besoin.
* Code
FIXME: Essayer de transformer ça en algo exact
FIXME: Mettre le code en adéquation avec le header
#+begin_src python :tangle DP_mu.py
from numpy import *
import scipy

g_fGamma = 0.9

def DP_mu( pi, Phi ):
    "Returns the matrix corresponding to the feature expectation of the given policy."
    global g_fGamma
    answer = scipy.rand( Phi.shape[0], Phi.shape[1] )
    changed = True
    while changed:
        new_answer = Phi + g_fGamma*dot(pi,answer)
        diff = sum( abs( new_answer - answer ) )
        answer = new_answer
        if diff > 0.00001:
            changed = True
        else:
            changed = False<
    return answer
#+end_src

* Makefile rules
  This file just needs to be tangled, we also provide the associateed cleaning rule.
  #+srcname: DP_mu_make
  #+begin_src makefile
DP_mu.py: DP_mu.org
	$(call tangle,"DP_mu.org")

DP_mu_clean:
	find . -maxdepth 1 -iname "DP_mu.py"   | xargs $(XARGS_OPT) rm
	find . -maxdepth 1 -iname "DP_mu.pyc"   | xargs $(XARGS_OPT) rm
  #+end_src

