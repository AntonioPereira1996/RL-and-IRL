#+TITLE:Using the code from Umar Syed

The code in the al_code directory was downloaded from :
http://www.cs.princeton.edu/~usyed/

The goal here is to make use of this code for comparison purposes.

* Putting an optimal policy in control of the simulator

The following octave code, mimmicking what I've read in the =al_code= fodler, should be able to save an optimal policy in the file =policy.dat=.

#+begin_src octave :tangle al_code/fast_policy.m
F = make_F;
THETA = make_THETA;
GAMMA = 0.9
w = [1.0 0 0]
VV = rand(N,K);
VV = sparse( VV );

[P, M, VV, ITER] = opt_policy_and_feat_exp( THETA, F, GAMMA, w, 'first', VV );

write_out_policy( PP(i,:) );
#+end_src

It relies on two octave functions, generated by a perl script, make_THETA and make_F :
#+srcname: MWAL_make
#+begin_src makefile
al_code/make_F.m: al_code/pre.pl
	pushd al_code; perl pre.pl ; popd

al_code/make_THETA.m: al_code/pre.pl
	pushd al_code; perl pre.pl ; popd
#+end_src

It can be invoked by :
#+srcname: MWAL_make
#+begin_src makefile
al_code/policy.dat: al_code/make_THETA.m al_code/make_F.m al_code/fast_policy.m
	pushd al_code; octave fast_policy.m ; popd
#+end_src

Now, the simulator can not directly use this file and it should be transformed using a perl script from the =al_code= directory.

#+srcname: MWAL_make
#+begin_src makefile
al_code/policy.txt: al_code/policy.dat
	pushd al_code; perl post.pl ; popd
#+end_src

Once the transformation is done, one can play with the policy in the simulator. We us our modified version which can stop after a certain number of transitions. We instantiate it with :
   #+begin_src python :tangle PolicyPlay.py
from App import *

root = Tk()
app = App(root)
app.autopilot = 'original'
app.max_t=200
root.mainloop()

   #+end_src

#+srcname: MWAL_make
#+begin_src makefile
Play: al_code/policy.txt
	cp al_code/policy.txt ./
	python PolicyPlay.py
#+end_src
