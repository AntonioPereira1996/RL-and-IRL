#+TITLE:Boosting SCIRL
#+LATEX_HEADER:\let\chapter\section
#+LATEX_HEADER:\usepackage[ruled,algo2e]{algorithm2e}
#+LATEX_HEADER:\usepackage{fullpage}
#+LATEX_HEADER:\usepackage{mathtools}
#+LATEX_HEADER:\mathtoolsset{showonlyrefs=false}
#+LATEX_HEADER:\usepackage{eulervm}
#+LATEX_HEADER:\usepackage{natbib}
#+begin_LaTeX
\newcommand{\prodsca}[2]{\mathopen{\langle}#1,#2\mathclose{\rangle}}
\newcommand{\Q}{Q^E_\psi}
#+end_LaTeX

* Making this document 						   :noexport:
  
#+srcname: SCIRLBoost_make
#+begin_src makefile 
SCIRLBoostCompile: SCIRLBoost.org
	emacs -batch --visit SCIRLBoost.org --funcall org-export-as-latex --script ~/.emacs
	pdflatex -interaction=batchmode SCIRLBoost.tex

SCIRLBoostStartView:
	xpdf -remote RTE1 SCIRLBoost.pdf

SCIRLBoostView:
	xpdf -remote RTE1 -reload

SCIRLBoostStopView:
	xpdf -remote RTE1 -quit

#+end_src
* SCIRL
** Données
   On suppose que l'on dispose de données échantillonnées selon la politique de l'expert. Il doit être possible d'étendre cette approche à un cas ressemblant à celui du cascadé, où l'on dispose également de données non expertes, mais cela suppose (pour LSTD-$\mu$ et LSTD-$Q$) de pouvoir évaluer la politique de l'expert sur un état arbitraire. Par soucis de simplicité d'exposition, on ne traite pas de ça ici.

   Les données sont recueillies sous la forme de transitions $s_i,a_i,s'_i,a'_i \in D_{sasa}$. L'on dispose aussi des ensembles $D_s = \{s_i|s_i,a_i,s'_i,a'_i \in D_{sasa}\}$, $D_{sa} = \{s_i,a_i|s_i,a_i,s'_i,a'_i \in D_{sasa}\}$ et $D_{s'a'} = \{s'_i,a'_i|s_i,a_i,s'_i,a'_i \in D_{sasa}\}$
** Features
*** Définitions
   La grandeur $\mu^E$ est la /feature expectation/ de l'expert. Elle est définie par :
\begin{equation}
\mu^E(s,a) = E\left[\left.\sum_t\psi_p(s_t)\right| s_0 = s,a_0 = a,\pi^E \right]
\end{equation}
où $\psi_p \in (\mathbb R^p)^S$ est une fonction de /feature/ vectorielle. On cherche ici à ne pas avoir à définir cette fonction par un travail d'ingénierie, mais à apprendre une bonne fonction $\psi_p$. Pour cela, on applique l'algorithme AnyBoost pour trouver une nouvelle composante $\psi$ telle que la nouvelle fonction de feature $\psi_{p+1} = \begin{bmatrix}\psi_p\\ \psi \end{bmatrix}$ génère un vecteur $\mu^E$ permettant à SCIRL de trouver une meilleure récompense.

A partir d'une fonction de feature $\psi_p \in (\mathbb R^p)^S$, on peut facilement définir une fonction de feature $\phi_k \in (\mathbb R^k)^{S\times A}$ par (avec $\delta$ le symbole de Kronecker) :
\begin{equation}
\phi(s,a) = \begin{bmatrix}\delta_{a,a_1}\psi_p(s)\\ \vdots \\ \delta_{a,a_{n_A}}\psi_p(s)\end{bmatrix}_{A=\{a_1..a_{n_A}\}}.
\end{equation}
*** Notation matricielle
Pour faciliter l'explication, on introduit les notations suivantes :
\begin{eqnarray}
\Psi_{D_s} &=& \begin{bmatrix}\vdots \\ \psi_p(s_i)^T \\ \vdots \end{bmatrix}_{s_i\in D_{s}}\\
\Phi_{D_{sa}} &=& \begin{bmatrix}\vdots \\ \phi(s_i,a_i)^T \\ \vdots \end{bmatrix}_{s_i,a_i\in D_{sa}}\\
\Phi_{D_{s'a'}} &=& \begin{bmatrix}\vdots \\ \phi(s'_i,a'_i)^T \\ \vdots \end{bmatrix}_{s'_i,a'_i\in D_{s'a'}}
\end{eqnarray}
** Pincipe
*** Fonction de risque
  SCIRL \citep{klein2012} minimise la fonction de risque :
\begin{eqnarray}
J(q) &=& \sum_{s_i,a_i\in D_{sa}}q(s_i,a_i^*)+l(s_i,a_i^*) - q(s_i,a_i),\\
\textrm{ avec : } q(s,a) &=& \theta^T\mu^E(s,a)\\
\textrm{ et : } a^*_i &=& \arg\max_a q(s_i,a) + l(s_i,a)
\end{eqnarray}
*** Evaluation de $\mu^E$
    Pour évaluer $\mu^E$ et donc permettre le calcul du sous-gradient et donc la minimisation du risque, deux techniques ont été utilisées.
    
    LSTD-$\mu$ \citep{klein2011batch} évalue $\mu^E$ par $\mu^E(s,a) = \Xi^T\phi(s,a)$ avec $\Xi = \Phi_{D_{sa}}(\Phi_{D_{sa}}-\gamma\Phi_{D_{s'a'}})^{-1}\Phi_{D_{sa}}\Psi_{D_{s}}$ et une technique de Monte-Carlo avec heuristique ne nécéssite que de connaître $\Psi_{D_s}$.

    Du fait de la manière dont sont constituées les matrices $\Phi$, et sachant que (si les données proviennent de trajectoires complètes) $D_s = D_{s'}$ à une réorganisation des indice près, quelle que soit la méthode choisie pour estimer $\mu^E$, il suffit de connaître $\Psi_{D_s}$.

    Au final, il est possible de faire tourner SCIRL non pas en utilisant une fonction de feature $\psi_p$, mais en utilisant la matrice $\Psi_{D_s}$ de la fonction $\psi$ évaluée sur les données disponibles.
* AnyBoost
  L'algo AnyBoost (\citet{mason1999functional} parallèlement à \citet{friedman2001greedy}) prescrit de chercher une nouvelle composante pour le vecteur $\mu^E$ telle que le produit scalaire de cette composante avec l'opposé du gradient fonctionnel de la fonction de risque soit maximal.
  
  Comme $\mu^E$ est la /feature expectation/, une composante de $\mu^E$ est une fonction de qualité pour la récompense égale à la composante du vecteur de /feature/ correspondant. L'on nomme $\psi \in \mathbb{R}^S$ la nouvelle composante que l'on cherche à booster dans SCIRL. La composante associée dans $\mu^E$ sera en conséquence de ce qu'on vient de dire notée $\Q$.
  
  Revenant à AnyBoost appliqué à SCIRL, il convient de trouver la nouvelle /feature component/ maximisant la quantité $\prodsca{-\nabla_qJ(q)}{\Q}$.

  Comme illustré dans MMPBoost \citep{ratliff2007boosting}, on peut identifier ce terme en écrivant le développement de $J(q + \epsilon \Q)$ ($J$ est linéaire, le développement s'arrête au premier ordre). Attention, on suppose ici que $\epsilon$ est suffisamment petit pour ne pas changer $a_i^*$.

  \begin{eqnarray}
  J(q + \epsilon Q^E_\psi) &=& J(q) + \epsilon \prodsca{\nabla_qJ(q)}{\Q}\\
&=&  \sum_{s_i,a_i\in D_{sa}}q(s_i,a_i^*)+l(s_i,a_i^*)+\epsilon \Q(s_i,a_i^*) - q(s_i,a_i)-\epsilon \Q(s_i,a_i)\\
&=&  \sum_{s_i,a_i\in D_{sa}}q(s_i,a_i^*)+l(s_i,a_i^*)- q(s_i,a_i) + \epsilon(\Q(s_i,a_i^*)-\Q(s_i,a_i))\\
&=&  J(q) + \epsilon \sum_{s_i,a_i\in D_{sa}} \Q(s_i,a_i^*)-\Q(s_i,a_i)\\
\Rightarrow \prodsca{-\nabla_qJ(q)}{\Q} &=& \sum_{s_i,a_i\in D_{sa}} \Q(s_i,a_i^*)-\Q(s_i,a_i).
  \end{eqnarray}

En conclusion, l'application de AnyBoost à SCIRL revient à résoudre le problème suivant de manière répétée :
\begin{eqnarray}
\label{eq:SCIRLBoost}
\psi &=& \arg\max_\psi \sum_{s_i,a_i\in D_{sa}^{\neq}} \Q(s_i,a_i^*)-\Q(s_i,a_i)\\
\textrm{ avec }D_{sa}^{\neq} &=& \{(s_i,a_i) \in D_{sa} | a_i \neq a_i^*\},
\end{eqnarray}
en effet, seuls les termes où $a_i \neq a_i^*$ comptent dans la somme puisque les autres sont nuls.
* Résolution avec LSTDQ
  Un schéma d'approximation linéaire de choix pour $\Q$ est $\Q(s,a) = \omega^T\mu^E(s,a)$. En utilisant LSTDQ \cite{lagoudakis2003least}, on obtient 
\begin{eqnarray}
\omega &=& \left[\sum_{s_i,a_i,s'_i,a'_i\in D_{sasa}} \mu^E(s_i,a_i)\left[\mu^E(s_i,a_i) - \gamma \mu_E(s'_i,a'_i) \right]\right]^{-1}\sum_{s_i,a_i\in D_{sa}} \mu_E(s_i,a_i) \psi(s_i).
\end{eqnarray}

On pose 
\begin{eqnarray}
\psi_D &=& \begin{bmatrix}\vdots \\ \psi(s_i) \\ \vdots \end{bmatrix}_{s_i\in D_{s}}\\
b &=& \begin{bmatrix}\vdots \\ \mu_E(s_i,a_i) \\ \vdots \end{bmatrix}_{s_i,a_i\in D_{sa}}\\
\textrm{ et } A &=& \left[\sum_{s_i,a_i,s'_i,a'_i\in D_{sasa}} \mu^E(s_i,a_i)\left[\mu^E(s_i,a_i) - \gamma \mu_E(s'_i,a'_i) \right]\right]^{-1}b.\\
\end{eqnarray}

On a donc maintenant $\omega = A\psi_{D} \Rightarrow \omega^T = \psi_{D}^T A^T$.

En reprenant l'équation \eqref{eq:SCIRLBoost} et en notant 
\begin{equation}
B = \sum_{s_i,a_i\in D_{sa}^{\neq}} \mu^E(s_i,a_i^*)-\mu^E(s_i,a_i),
\end{equation}
on obtient :
\begin{eqnarray}
\psi &=& \arg\max_\psi \sum_{s_i,a_i\in D_{sa}^{\neq}} \Q(s_i,a_i^*)-\Q(s_i,a_i)\\
\psi &=& \arg\max_\psi \sum_{s_i,a_i\in D_{sa}^{\neq}} \omega^T\mu^E(s_i,a_i^*)-\omega^T\mu^E(s_i,a_i)\\
\psi &=& \arg\max_\psi \sum_{s_i,a_i\in D_{sa}^{\neq}} \omega^T(\mu^E(s_i,a_i^*)-\mu^E(s_i,a_i))\\
\psi &=& \arg\max_\psi \omega^T \sum_{s_i,a_i\in D_{sa}^{\neq}} \mu^E(s_i,a_i^*)-\mu^E(s_i,a_i)\\
\psi &=& \arg\max_\psi \psi_{D}^T A^TB
\end{eqnarray}
Bien que ça ne résolve pas exactement le problème posé, l'on peut déjà noter que (en normant \psi_{D}) :
\begin{eqnarray}
\arg\max_{\psi_{D}} \psi_{D}^T A^TB = {A^TB\over ||A^TB||}.
\end{eqnarray}
* SCIRLBoost
Avec tout ceci, il est possible de faire tourner SCIRL de manière répétée en injectant une nouvelle composante à $\psi_p$ à chaque itération. L'on obtiendra à la fin non pas une fonction de récompense $R \in \mathbb R ^S$ mais une matrice $\mathbf R _{D_s}$ de cette fonction de récompense évaluée sur les données disponibles. Il faut trouver un moyen de généraliser tout cela à tout l'espace d'état si nécessaire.



\begin{algorithm2e}%[tbh]
  \SetAlgoVlined
  \caption{SCIRLBoost}
  \label{algo:scirl}
  \BlankLine
  \emph{\textbf{Initialiser}} p \leftarrow 1 \; 
  \BlankLine
  \emph{\textbf{Initialiser}} $\Psi_{D_s}\in \mathbb R^{|D|}$ aléatoirement \; 
  \BlankLine
  \emph{\textbf{Tant que }} $D^{\neq}_{sa}$ n'est pas vide \;
  \BlankLine
  \hspace{1em} \emph{\textbf{Calculer}} $\theta$ avec SCIRL\;
  \BlankLine
  \hspace{1em} \emph{\textbf{Redéfinir}} $p \leftarrow p+1$ \;
  \BlankLine
  \hspace{1em} \emph{\textbf{Redéfinir}} $\Psi_{D_s} \leftarrow \begin{bmatrix}\Psi_{D_s},\psi_D = {A^TB\over ||A^TB||}\end{bmatrix}$ \;
  \BlankLine
  \emph{\textbf{Retourner}} la matrice $\mathbf R_{D_s} = \theta^T\Psi_{D_s}^T$ \;
\end{algorithm2e}

Dans le cas d'un espace d'état fini, où tous les états sont visités par l'expert dans les données à disposition, il est peut-être possible d'obtenir un fonction $\psi_p$ (complètement décrite par la matrice $\mathbf{R}_{D_s}$ ) dont la dimension est moindre que les features tabulaires habituelles (c'est à dire que $p < |S|$). Dans les autres cas, il faut trouver un moyen de généraliser $\mathbf R_{D_s}$ en $\psi_p \in (\mathbb R^p)^S$.


\bibliographystyle{plainnat}
\bibliography{../Biblio/Biblio.bib}
* Trucs à faire sur ce document :noexport:
** TODO Rédiger dans un langage compréhensible par des gens non familier avec SCIRL
** DONE Rajouter les \cite et une vraie biblio
   CLOSED: [2012-11-21 mer. 15:37]
   lagoudakis, MMPBoost, Mason et Friedman, SCIRL
** TODO Résoudre conflit de notation A la matrice et A l'espace d'actions
