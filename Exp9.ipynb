{
 "metadata": {
  "name": "Exp9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from stuff import *\n",
      "from pylab import *\n",
      "from random import *\n",
      "import numpy\n",
      "from rl import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Psi = genfromtxt('asterix/psi.mat')\n",
      "A = genfromtxt('asterix/actions.mat')\n",
      "A = A.reshape((len(A),1))\n",
      "ACTION_SPACE = range(0,18)\n",
      "Psi.shape,A.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "((325, 1000), (325, 1))"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Classification code\n",
      "def greedy_policy( omega, phi, A ): \n",
      "    def policy( *args ):\n",
      "        state_actions = [hstack(args+(a,)) for a in A]\n",
      "        q_value = lambda sa: float(dot(omega.transpose(),phi(sa)))\n",
      "        best_action = argmax( state_actions, q_value )[-1] #FIXME6: does not work for multi dimensional actions\n",
      "        return best_action\n",
      "    vpolicy = non_scalar_vectorize( policy, (1000,), (1,1) ) #FIXME, the 1000 here is s_dim and is problem-dependant\n",
      "    return lambda state: vpolicy(state).reshape(state.shape[:-1]+(1,))\n",
      "\n",
      "#Structured Classifier\n",
      "class GradientDescent(object):\n",
      "    \n",
      "   def alpha( self, t ):\n",
      "      raise NotImplementedError, \"Cannot call abstract method\"\n",
      "\n",
      "   theta_0=None\n",
      "   Threshold=None\n",
      "   T = -1\n",
      "   sign = None\n",
      "        \n",
      "   def run( self, f_grad, f_proj=None, b_norm=False ): #grad is a function of theta\n",
      "      theta = self.theta_0.copy()\n",
      "      best_theta = theta.copy()\n",
      "      best_norm = float(\"inf\")\n",
      "      best_iter = 0\n",
      "      t=0\n",
      "      while True:#Do...while loop\n",
      "         t+=1\n",
      "         DeltaTheta = f_grad( theta )\n",
      "         current_norm = norm( DeltaTheta )\n",
      "         if b_norm and  current_norm > 0.:\n",
      "             DeltaTheta /= norm( DeltaTheta )\n",
      "         theta = theta + self.sign * self.alpha( t )*DeltaTheta\n",
      "         if f_proj:\n",
      "             theta = f_proj( theta )\n",
      "         print \"Norme du gradient : \"+str(current_norm)+\", pas : \"+str(self.alpha(t))+\", iteration : \"+str(t)\n",
      "\n",
      "         if current_norm < best_norm:\n",
      "             best_norm = current_norm\n",
      "             best_theta = theta.copy()\n",
      "             best_iter = t\n",
      "         if current_norm < self.Threshold or (self.T != -1 and t >= self.T):\n",
      "             break\n",
      "\n",
      "      print \"Gradient de norme : \"+str(best_norm)+\", a l'iteration : \"+str(best_iter)\n",
      "      return best_theta\n",
      "\n",
      "\n",
      "class StructuredClassifier(GradientDescent):\n",
      "    sign=-1.\n",
      "    Threshold=0.1 #Sensible default\n",
      "    T=10 #Sensible default\n",
      "    phi=None\n",
      "    phi_xy=None\n",
      "    inputs=None\n",
      "    labels=None\n",
      "    label_set=None\n",
      "    dic_data={}\n",
      "    x_dim=None\n",
      "    \n",
      "    def alpha(self, t):\n",
      "        return 3./(t+1)#Sensible default\n",
      "    \n",
      "    def __init__(self, data, x_dim, phi, phi_dim, Y):\n",
      "        self.x_dim=x_dim\n",
      "        self.inputs = data[:,:-1]\n",
      "        shape = list(data.shape)\n",
      "        shape[-1] = 1\n",
      "        self.labels = data[:,-1].reshape(shape)\n",
      "        self.phi=phi\n",
      "        self.label_set = Y\n",
      "        self.theta_0 = zeros((phi_dim,1))\n",
      "        self.phi_xy = self.phi(data)\n",
      "        for x,y in zip(self.inputs,self.labels):\n",
      "            self.dic_data[str(x)] = y\n",
      "        print self.inputs.shape\n",
      "    \n",
      "    def structure(self, xy):\n",
      "        return 0. if xy[-1] == self.dic_data[str(xy[:-1])] else 1.\n",
      "        \n",
      "    def structured_decision(self, theta):\n",
      "        def decision( x ):\n",
      "            score = lambda xy: dot(theta.transpose(),self.phi(xy)) + self.structure(xy)\n",
      "            input_label_couples = [hstack([x,y]) for y in self.label_set]\n",
      "            best_label = argmax(input_label_couples, score)[-1]\n",
      "            return best_label\n",
      "        vdecision = non_scalar_vectorize(decision, (self.x_dim,), (1,1))\n",
      "        return lambda x: vdecision(x).reshape(x.shape[:-1]+(1,))\n",
      "    \n",
      "    def gradient(self, theta):\n",
      "        classif_rule = self.structured_decision(theta)\n",
      "        y_star = classif_rule(self.inputs)\n",
      "        #print \"Gradient : \"+str(y_star)\n",
      "        #print str(self.labels)\n",
      "        phi_star = self.phi(hstack([self.inputs,y_star]))\n",
      "        return mean(phi_star-self.phi_xy,axis=0)\n",
      "    \n",
      "    def run(self):\n",
      "        f_grad = lambda theta: self.gradient(theta)\n",
      "        theta = super(StructuredClassifier,self).run( f_grad, b_norm=True)\n",
      "        classif_rule = greedy_policy(theta,self.phi,self.label_set)\n",
      "        return classif_rule,theta\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Running the classifier gives pi_c and q\n",
      "def asterix_single_phi(psi_a):\n",
      "    psi = psi_a[:1000]\n",
      "    a = psi_a[-1]\n",
      "    answer = zeros((18000,1))\n",
      "    index = a*1000\n",
      "    answer[index:index+1000,0] = psi\n",
      "    return answer\n",
      "asterix_phi = non_scalar_vectorize(asterix_single_phi, (1001,), (18000,1))\n",
      "clf = StructuredClassifier(hstack([Psi,A]), 1000, asterix_phi, 18000, ACTION_SPACE)\n",
      "pi_c,theta_C = clf.run()\n",
      "q = lambda sa: squeeze(dot(theta_C.transpose(),asterix_phi(sa)))\n",
      "savetxt(\"CSI_asterix_theta_C.mat\", theta_C)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1047, 1000)\n",
        "Norme du gradient : 27.9556519663, pas : 1.5, iteration : 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Gradient de norme : 27.9556519663, a l'iteration : 1\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Regressor code\n",
      "q = lambda sa: squeeze(dot(theta_C.transpose(),asterix_phi(sa)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Running the regressio code yelds 18 theta matrices, one per action\n",
      "column_shape = (len(Psi)-1,1)\n",
      "s = Psi[:-1,:]\n",
      "s.shape\n",
      "a = A[:-1].reshape(column_shape)\n",
      "sa = hstack([s,a])\n",
      "s_dash = Psi[1:,:]\n",
      "a_dash = pi_c(s_dash).reshape(column_shape)\n",
      "sa_dash = hstack([s_dash,a_dash])\n",
      "hat_r = (q(sa)-GAMMA*q(sa_dash)).reshape(column_shape)\n",
      "r_min = min(hat_r)-1.*ones(column_shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thetas = zeros((18,1000))\n",
      "for action in ACTION_SPACE:\n",
      "    X = s\n",
      "    hat_r_bool_table = array(a==action)\n",
      "    r_min_bool_table = array(hat_r_bool_table==False) #\"not hat_r_bool_table\" does not work as I expected\n",
      "    Y =  hat_r_bool_table*hat_r + r_min_bool_table*r_min\n",
      "    thetas[action] = squeeze( dot(dot(inv(dot(X.transpose(),X)+0.1*identity(X.shape[1])),X.transpose()),Y) )\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "savetxt(\"CSI_asterix_thetas.mat\", thetas)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    }
   ],
   "metadata": {}
  }
 ]
}