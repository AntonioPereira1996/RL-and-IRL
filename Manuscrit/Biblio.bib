
@conference{taskar2005learning,
	Annote = {Cit{\'e} dans \cite{ratliff2007boosting}.
Th{\`e}se de Taskar.
Il choisit les approches {\`a} marges (e.g. SVM) par rapport aux approches bay{\'e}siennes. On part des donn{\'e}es (inputs, labels), on apprend un mod{\`e}le (via une approche {\`a} marge) tel que la r{\'e}solution du mod{\`e}le (via dynamic programming, par exemple) donne un r{\`e}gle g{\'e}n{\'e}ralisant les donn{\'e}es.
L'{\'e}quation 4.2 est {\'e}quivalente {\`a} l'{\'e}quation 2.9/2.10, c{\`a}d une SVM.
},
	Author = {Taskar, B. and Chatalbashev, V. and Koller, D. and Guestrin, C.},
	Booktitle = {Proceedings of the 22nd international conference on Machine learning},
	Date-Added = {2010-09-03 10:56:14 +0200},
	Date-Modified = {2012-11-15 14:16:28 +0000},
	Keywords = {Toto},
	Organization = {ACM},
	Pages = {903},
	Read = {1},
	Title = {Learning structured prediction models: A large margin approach},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHlBhcGllcnMvdGFza2FyMjAwNWxlYXJuaW5nLnBkZtIXCxgZV05TLmRhdGFPEQHqAAAAAAHqAAIAAAVTbGFzaAAAAAAAAAAAAAAAAAAAAAAAAAAAAADM9OTPSCsAAAAHTD4WdGFza2FyMjAwNWxlYXJuaW5nLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAdMesqZB4wAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAAB1BhcGllcnMAABAACAAAzPTWvwAAABEACAAAypjrbAAAAAEAIAAHTD4AB0ccAAdHGgAHPW8ABy76AAcdNQAHCDwABwg5AAIAX1NsYXNoOlVzZXJzOgBlZG91YXJkOgBEb2N1bWVudHM6AE1pZW5zOgBUcmF2YWlsOgBUaGVzZToAQmlibGlvOgBQYXBpZXJzOgB0YXNrYXIyMDA1bGVhcm5pbmcucGRmAAAOAC4AFgB0AGEAcwBrAGEAcgAyADAAMAA1AGwAZQBhAHIAbgBpAG4AZwAuAHAAZABmAA8ADAAFAFMAbABhAHMAaAASAFFVc2Vycy9lZG91YXJkL0RvY3VtZW50cy9NaWVucy9UcmF2YWlsL1RoZXNlL0JpYmxpby9QYXBpZXJzL3Rhc2thcjIwMDVsZWFybmluZy5wZGYAABMAAS8AABUAAgAO//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArwC0ALwCqgKsArECvALFAtMC1wLeAucC7AL5AvwDDgMRAxYAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADGA==}}


@article{safavian1991survey,
  title={A survey of decision tree classifier methodology},
  author={Safavian, S Rasoul and Landgrebe, David},
  journal={Systems, Man and Cybernetics, IEEE Transactions on},
  volume={21},
  number={3},
  pages={660--674},
  year={1991},
  publisher={IEEE}
}


@conference{russell1998learning,
	Annote = {Cit{\'e} de \cite{ng2000algorithms} :
	"The IRL problem can be characterized informally as follows."},
	Author = {Russell, S.},
	Booktitle = {Annual Conference on Computational Learning Theory},
	Cites1 = {sutton1988learning,kaelbling1996reinforcement,bertsekas1996neuro,watkins1989learning, astrom1965optimal,dean1989model,binder1997adaptive,friedman1998learning,kanazawa1995stochastic,boyen1998tractable,binder1997space,parr1998reinforcement},
	Cites2 = {parr1995approximating,mccallum1993overcoming},
	Cites3 = {russell1995modern,schmajuk1997escape,touretzky1997operant,montague1995bee,doya1995novel,hoyt1981gait,farley1991mechanical,keeney1976decision,sargent1978estimation,rust1994people},
	Comprehension = {1},
	Date-Added = {2010-09-02 09:30:20 +0200},
	Date-Modified = {2012-03-16 09:54:41 +0000},
	Keywords = {IRL,Toto},
	Organization = {ACM},
	Pages = {103},
	Read = {1},
	Title = {Learning agents for uncertain environments (extended abstract)},
	Year = {1998},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAeoAAAAAAeoAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbBZydXNzZWwxOTk4bGVhcm5pbmcucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXGdypkHiwAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADKmOtrAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBfU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AHJ1c3NlbDE5OThsZWFybmluZy5wZGYAAA4ALgAWAHIAdQBzAHMAZQBsADEAOQA5ADgAbABlAGEAcgBuAGkAbgBnAC4AcABkAGYADwAMAAUAUwBsAGEAcwBoABIAUVVzZXJzL2Vkb3VhcmQvRG9jdW1lbnRzL01pZW5zL1RyYXZhaWwvVGhlc2UvQmlibGlvL1BhcGllcnMvcnVzc2VsMTk5OGxlYXJuaW5nLnBkZgAAEwABLwAAFQACAA7//wAAgAXSHB0eH1gkY2xhc3Nlc1okY2xhc3NuYW1lox8gIV1OU011dGFibGVEYXRhVk5TRGF0YVhOU09iamVjdF8QHlBhcGllcnMvcnVzc2VsMTk5OGxlYXJuaW5nLnBkZtIcHSQloiUhXE5TRGljdGlvbmFyeRIAAYagXxAPTlNLZXllZEFyY2hpdmVyAAgAEQAWAB8AKAAyADUAOgA8AEUASwBSAF0AZQBsAG8AcQBzAHYAeAB6AHwAhgCTAJgAoAKOApAClQKeAqkCrQK7AsICywLsAvEC9AMBAwYAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADGA==}}

@conference{ng2000algorithms,
	Annote = {Cit{\'e} de \cite{abbeel2004apprenticeship} :
	"inverse reinforcement learning."
Cit{\'e} dans \cite{ziebart2008maximum} :
	"Each policy can be optimal for many reward functions and many policies lead to the same feature counts."},
	Author = {Ng, A.Y. and Russell, S.},
	Booktitle = {International Conference on Machine Learning (ICML)},
	Cited-By = {abbeel2004apprenticeship,ziebart2008maximum},
	Cites1 = {russell1998learning},
	Cites3 = {sutton1998reinforcement,bertsekas1996neuro,doya1995novel,montague1995bee,boyd1994linear,rust1994people,sargent1978estimation,keeney1976decision,touretzky1997operant,schmajuk1997escape,watkins1989models},
	Cites4 = {ng1999policy},
	Comprehension = {1},
	Date-Added = {2010-09-01 17:13:32 +0200},
	Date-Modified = {2012-03-16 09:52:33 +0000},
	Keywords = {IRL},
	Organization = {Morgan Kaufmann Publishers Inc.},
	Pages = {663--670},
	Read = {1},
	Title = {Algorithms for inverse reinforcement learning},
	Year = {2000},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAboAAAAAAboAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbApOZzIwMDAucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXGSypkHfAAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADKmOtcAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBTU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AE5nMjAwMC5wZGYAAA4AFgAKAE4AZwAyADAAMAAwAC4AcABkAGYADwAMAAUAUwBsAGEAcwBoABIARVVzZXJzL2Vkb3VhcmQvRG9jdW1lbnRzL01pZW5zL1RyYXZhaWwvVGhlc2UvQmlibGlvL1BhcGllcnMvTmcyMDAwLnBkZgAAEwABLwAAFQACAA7//wAAgAXSHB0eH1gkY2xhc3Nlc1okY2xhc3NuYW1lox8gIV1OU011dGFibGVEYXRhVk5TRGF0YVhOU09iamVjdF8QElBhcGllcnMvTmcyMDAwLnBkZtIcHSQloiUhXE5TRGljdGlvbmFyeRIAAYagXxAPTlNLZXllZEFyY2hpdmVyAAgAEQAWAB8AKAAyADUAOgA8AEUASwBSAF0AZQBsAG8AcQBzAHYAeAB6AHwAhgCTAJgAoAJeAmACZQJuAnkCfQKLApICmwKwArUCuALFAsoAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC3A==}}


@conference{abbeel2004apprenticeship,
	Annote = {Cit{\'e} dans \cite{ziebart2008maximum} :
	"Each policy can be optimal for many reward functions and many policies lead to the same feature counts."},
	Author = {Abbeel, P. and Ng, A.Y.},
	Booktitle = {International Conference on Machine Learning (ICML)},
	Cited-By = {ziebart2008maximum},
	Cites1 = {ng2000algorithms},
	Cites2 = {atkeson1997robot,pomerleau1989alvinn,amit2002learning,demiris1994robot,kuniyoshi1994learning,sammut1992learning,ng1999policy},
	Cites3 = {uno1989formation,vapnik1998statistical,hogan1984organizing,rockafellar1970convex},
	Comprehension = {1},
	Date-Added = {2010-09-01 15:30:24 +0200},
	Date-Modified = {2012-03-16 09:41:44 +0000},
	Keywords = {IRL,Toto},
	Organization = {ACM},
	Pages = {1},
	Read = {1},
	Title = {Apprenticeship learning via inverse reinforcement learning},
	Year = {2004},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAcoAAAAAAcoAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbA5BYmJlZWwyMDA0LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXFuypkHewAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADKmOtbAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBXU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AEFiYmVlbDIwMDQucGRmAAAOAB4ADgBBAGIAYgBlAGUAbAAyADAAMAA0AC4AcABkAGYADwAMAAUAUwBsAGEAcwBoABIASVVzZXJzL2Vkb3VhcmQvRG9jdW1lbnRzL01pZW5zL1RyYXZhaWwvVGhlc2UvQmlibGlvL1BhcGllcnMvQWJiZWVsMjAwNC5wZGYAABMAAS8AABUAAgAO//8AAIAF0hwdHh9YJGNsYXNzZXNaJGNsYXNzbmFtZaMfICFdTlNNdXRhYmxlRGF0YVZOU0RhdGFYTlNPYmplY3RfEBZQYXBpZXJzL0FiYmVlbDIwMDQucGRm0hwdJCWiJSFcTlNEaWN0aW9uYXJ5EgABhqBfEA9OU0tleWVkQXJjaGl2ZXIACAARABYAHwAoADIANQA6ADwARQBLAFIAXQBlAGwAbwBxAHMAdgB4AHoAfACGAJMAmACgAm4CcAJ1An4CiQKNApsCogKrAsQCyQLMAtkC3gAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALw}}


	
@conference{syed2008apprenticeship,
	Author = {Syed, U. and Bowling, M. and Schapire, R.E.},
	Booktitle = {International Conference on Machine Learning (ICML)},
	Cites1 = {abbeel2004apprenticeship,syed2008game},
	Cites2 = {ratliff2006maximum},
	Cites3 = {puterman1994markov,feinberg2002handbook,fang1993linear,grant2008cvx,johanson2008computing,wang2008stable},
	Comprehension = {-},
	Date-Added = {2011-03-28 14:47:09 +0200},
	Date-Modified = {2012-03-16 09:56:44 +0000},
	Keywords = {IRL,Toto},
	Organization = {ACM},
	Pages = {1032--1039},
	Read = {1},
	Title = {Apprenticeship learning using linear programming},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAfoAAAAAAfoAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbBpzeWVkMjAwOGFwcHJlbnRpY2VzaGlwLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXGjypkHiwAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADKmOtrAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBjU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AHN5ZWQyMDA4YXBwcmVudGljZXNoaXAucGRmAAAOADYAGgBzAHkAZQBkADIAMAAwADgAYQBwAHAAcgBlAG4AdABpAGMAZQBzAGgAaQBwAC4AcABkAGYADwAMAAUAUwBsAGEAcwBoABIAVVVzZXJzL2Vkb3VhcmQvRG9jdW1lbnRzL01pZW5zL1RyYXZhaWwvVGhlc2UvQmlibGlvL1BhcGllcnMvc3llZDIwMDhhcHByZW50aWNlc2hpcC5wZGYAABMAAS8AABUAAgAO//8AAIAF0hwdHh9YJGNsYXNzZXNaJGNsYXNzbmFtZaMfICFdTlNNdXRhYmxlRGF0YVZOU0RhdGFYTlNPYmplY3RfECJQYXBpZXJzL3N5ZWQyMDA4YXBwcmVudGljZXNoaXAucGRm0hwdJCWiJSFcTlNEaWN0aW9uYXJ5EgABhqBfEA9OU0tleWVkQXJjaGl2ZXIACAARABYAHwAoADIANQA6ADwARQBLAFIAXQBlAGwAbwBxAHMAdgB4AHoAfACGAJMAmACgAp4CoAKlAq4CuQK9AssC0gLbAwADBQMIAxUDGgAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMs}}


@conference{ratliff2006maximum,
	Abstract = {Rien bit{\'e}. A relire.},
	Annote = {Cit{\'e} dans \cite{ziebart2008maximum} :
	"We discuss several additional advantages in modeling behavior that this technique has over existing approaches to inverse reinforcement learning."
Cit{\'e} dans \cite{ratliff2007boosting}.},
	Author = {Ratliff, N.D. and Bagnell, J.A. and Zinkevich, M.A.},
	Booktitle = {International Conference on Machine Learning (ICML)},
	Cites1 = {taskar2005learning,nedic2000convergence},
	Cites2 = {pomerleau1989alvinn,lecun2006off,abbeel2004apprenticeship},
	Cites3 = {tsochantaridis2006large,taskar2003max,rifkin2003regularized,hebert1998mobility,puterman1994markov,shor1985minimization},
	Date-Added = {2010-09-02 14:07:55 +0200},
	Date-Modified = {2012-03-16 09:54:20 +0000},
	Keywords = {IRL,Toto},
	Organization = {ACM},
	Pages = {736},
	Read = {1},
	Title = {Maximum margin planning},
	Year = {2006},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAcwAAAAAAcwAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbA9SYXRsaWZmMjAwNi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXGXypkHfAAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADKmOtcAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBYU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AFJhdGxpZmYyMDA2LnBkZgAOACAADwBSAGEAdABsAGkAZgBmADIAMAAwADYALgBwAGQAZgAPAAwABQBTAGwAYQBzAGgAEgBKVXNlcnMvZWRvdWFyZC9Eb2N1bWVudHMvTWllbnMvVHJhdmFpbC9UaGVzZS9CaWJsaW8vUGFwaWVycy9SYXRsaWZmMjAwNi5wZGYAEwABLwAAFQACAA7//wAAgAXSHB0eH1gkY2xhc3Nlc1okY2xhc3NuYW1lox8gIV1OU011dGFibGVEYXRhVk5TRGF0YVhOU09iamVjdF8QF1BhcGllcnMvUmF0bGlmZjIwMDYucGRm0hwdJCWiJSFcTlNEaWN0aW9uYXJ5EgABhqBfEA9OU0tleWVkQXJjaGl2ZXIACAARABYAHwAoADIANQA6ADwARQBLAFIAXQBlAGwAbwBxAHMAdgB4AHoAfACGAJMAmACgAnACcgJ3AoACiwKPAp0CpAKtAscCzALPAtwC4QAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALz}}


@conference{neu2007apprenticeship,
	Annote = {Cit{\'e} dans \cite{ziebart2008maximum} :
	"We discuss several additional advantages in modeling behavior that this technique has over existing approaches to inverse reinforcement learning."},
	Author = {Neu, G. and Szepesv{\'a}ri, C.},
	Booktitle = {Conference on Uncertainty in Artificial Intelligence (UAI)},
	Cites1 = {ng2000algorithms},
	Cites2 = {abbeel2004apprenticeship,riedmiller1993direct,igel2000improving,ratliff2006maximum},
	Cites3 = {puterman1994markov,gyorfi2002distribution,vanderbeioptimal},
	Comprehension = {-},
	Date-Added = {2010-09-02 14:12:59 +0200},
	Date-Modified = {2012-03-16 09:51:26 +0000},
	Keywords = {IRL},
	Pages = {295--302},
	Read = {1},
	Title = {Apprenticeship learning using inverse reinforcement learning and gradient methods},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAfQAAAAAAfQAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbBluZXUyMDA3YXBwcmVudGljZXNoaXAucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXGPypkHhQAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADKmOtlAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBiU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AG5ldTIwMDdhcHByZW50aWNlc2hpcC5wZGYADgA0ABkAbgBlAHUAMgAwADAANwBhAHAAcAByAGUAbgB0AGkAYwBlAHMAaABpAHAALgBwAGQAZgAPAAwABQBTAGwAYQBzAGgAEgBUVXNlcnMvZWRvdWFyZC9Eb2N1bWVudHMvTWllbnMvVHJhdmFpbC9UaGVzZS9CaWJsaW8vUGFwaWVycy9uZXUyMDA3YXBwcmVudGljZXNoaXAucGRmABMAAS8AABUAAgAO//8AAIAF0hwdHh9YJGNsYXNzZXNaJGNsYXNzbmFtZaMfICFdTlNNdXRhYmxlRGF0YVZOU0RhdGFYTlNPYmplY3RfECFQYXBpZXJzL25ldTIwMDdhcHByZW50aWNlc2hpcC5wZGbSHB0kJaIlIVxOU0RpY3Rpb25hcnkSAAGGoF8QD05TS2V5ZWRBcmNoaXZlcgAIABEAFgAfACgAMgA1ADoAPABFAEsAUgBdAGUAbABvAHEAcwB2AHgAegB8AIYAkwCYAKACmAKaAp8CqAKzArcCxQLMAtUC+QL+AwEDDgMTAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAyU=}}


@conference{ziebart2008maximum,
	Author = {Ziebart, B.D. and Maas, A. and Bagnell, J.A. and Dey, A.K.},
	Booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
	Cites1 = {jaynes1957information},
	Cites2 = {ratliff2006maximum,ramachandran2007bayesian,neu2007apprenticeship,abbeel2004apprenticeship,ng1999policy,liao2007learning},
	Cites3 = {lafferty2001conditional,dudik2006maximum,krumm2006predestination,letchner2006trip},
	Comprehension = {0},
	Date-Added = {2010-09-02 14:02:00 +0200},
	Date-Modified = {2012-03-16 09:58:13 +0000},
	Keywords = {IRL},
	Pages = {1433--1438},
	Read = {1},
	Title = {Maximum entropy inverse reinforcement learning},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAcwAAAAAAcwAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbA9aaWViYXJ0MjAwOC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXGrypkHfgAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADKmOteAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBYU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AFppZWJhcnQyMDA4LnBkZgAOACAADwBaAGkAZQBiAGEAcgB0ADIAMAAwADgALgBwAGQAZgAPAAwABQBTAGwAYQBzAGgAEgBKVXNlcnMvZWRvdWFyZC9Eb2N1bWVudHMvTWllbnMvVHJhdmFpbC9UaGVzZS9CaWJsaW8vUGFwaWVycy9aaWViYXJ0MjAwOC5wZGYAEwABLwAAFQACAA7//wAAgAXSHB0eH1gkY2xhc3Nlc1okY2xhc3NuYW1lox8gIV1OU011dGFibGVEYXRhVk5TRGF0YVhOU09iamVjdF8QF1BhcGllcnMvWmllYmFydDIwMDgucGRm0hwdJCWiJSFcTlNEaWN0aW9uYXJ5EgABhqBfEA9OU0tleWVkQXJjaGl2ZXIACAARABYAHwAoADIANQA6ADwARQBLAFIAXQBlAGwAbwBxAHMAdgB4AHoAfACGAJMAmACgAnACcgJ3AoACiwKPAp0CpAKtAscCzALPAtwC4QAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALz}}


@article{neu2009training,
	Author = {Neu, G. and Szepesv{\'a}ri, C.},
	Cites1 = {ng2000algorithms,abbeel2004apprenticeship,syed2008game,neu2007apprenticeship,ratliff2006maximum,ziebart2008maximum},
	Cites3 = {bakir2007predicting,manning2000foundations,charniak2005coarse,rivas1999dynamic,elliott1984application,collins2002discriminative,taskar2005learning,maes2007sequence,daume2006practical,klein2003parsing,turian2006advances,titov2007constituent,boyd1994linear,warmuth1997continuous,taskar2004max,freund1999large,collins2004incremental},
	Comprehension = {-},
	Date-Added = {2010-09-09 11:16:21 +0200},
	Date-Modified = {2012-03-16 09:52:05 +0000},
	Journal = {Machine learning},
	Keywords = {IRL,Toto},
	Number = {2},
	Pages = {303--337},
	Publisher = {Springer},
	Read = {1},
	Title = {Training parsers by inverse reinforcement learning},
	Volume = {77},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAbwAAAAAAbwAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbAtOZXUyMDA5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXGQypkHfAAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADKmOtcAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBUU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AE5ldTIwMDkucGRmAA4AGAALAE4AZQB1ADIAMAAwADkALgBwAGQAZgAPAAwABQBTAGwAYQBzAGgAEgBGVXNlcnMvZWRvdWFyZC9Eb2N1bWVudHMvTWllbnMvVHJhdmFpbC9UaGVzZS9CaWJsaW8vUGFwaWVycy9OZXUyMDA5LnBkZgATAAEvAAAVAAIADv//AACABdIcHR4fWCRjbGFzc2VzWiRjbGFzc25hbWWjHyAhXU5TTXV0YWJsZURhdGFWTlNEYXRhWE5TT2JqZWN0XxATUGFwaWVycy9OZXUyMDA5LnBkZtIcHSQloiUhXE5TRGljdGlvbmFyeRIAAYagXxAPTlNLZXllZEFyY2hpdmVyAAgAEQAWAB8AKAAyADUAOgA8AEUASwBSAF0AZQBsAG8AcQBzAHYAeAB6AHwAhgCTAJgAoAJgAmICZwJwAnsCfwKNApQCnQKzArgCuwLIAs0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC3w==}}



@article{ramachandran2007bayesian,
	Annote = {Cit{\'e} dans \cite{ziebart2008maximum} :
	"We discuss several additional advantages in modeling behavior that this technique has over existing approaches to inverse reinforcement learning."},
	Author = {Ramachandran, D. and Amir, E.},
	Cites1 = {ng2000algorithms,vempala2005geometric,cipra1987introduction,russell1998learning},
	Cites2 = {atkeson1997robot,abbeel2004apprenticeship,price2003bayesian},
	Cites3 = {rust1994people,billings1998opponent,sutton1998reinforcement,berger1985statistical,applegate1991sampling,tarantola2005inverse,boyd1994linear},
	Comprehension = {0},
	Date-Added = {2010-09-02 14:11:11 +0200},
	Date-Modified = {2012-03-16 09:53:47 +0000},
	Journal = {Proceedings of the International Joint Conference on Artificial Intelligence},
	Keywords = {IRL,Toto},
	Pages = {2586--2591},
	Read = {1},
	Title = {Bayesian inverse reinforcement learning},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAeIAAAAAAeIAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbBRSYW1hY2hhbmRyYW4yMDA3LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXGWypkHfAAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADKmOtcAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBdU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AFJhbWFjaGFuZHJhbjIwMDcucGRmAAAOACoAFABSAGEAbQBhAGMAaABhAG4AZAByAGEAbgAyADAAMAA3AC4AcABkAGYADwAMAAUAUwBsAGEAcwBoABIAT1VzZXJzL2Vkb3VhcmQvRG9jdW1lbnRzL01pZW5zL1RyYXZhaWwvVGhlc2UvQmlibGlvL1BhcGllcnMvUmFtYWNoYW5kcmFuMjAwNy5wZGYAABMAAS8AABUAAgAO//8AAIAF0hwdHh9YJGNsYXNzZXNaJGNsYXNzbmFtZaMfICFdTlNNdXRhYmxlRGF0YVZOU0RhdGFYTlNPYmplY3RfEBxQYXBpZXJzL1JhbWFjaGFuZHJhbjIwMDcucGRm0hwdJCWiJSFcTlNEaWN0aW9uYXJ5EgABhqBfEA9OU0tleWVkQXJjaGl2ZXIACAARABYAHwAoADIANQA6ADwARQBLAFIAXQBlAGwAbwBxAHMAdgB4AHoAfACGAJMAmACgAoYCiAKNApYCoQKlArMCugLDAuIC5wLqAvcC/AAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMO}}


@inproceedings{chajewska2001learning,
	Author = {Chajewska, U. and Koller, D. and Ormoneit, D.},
	Booktitle = {International Conference on Machine Learning (ICML)},
	Cites1 = {applegate1991sampling},
	Cites2 = {ng2000algorithms},
	Cites3 = {von1944theory,fromberg1989methodology,chajewska2000utilities,pearl1988probabilistic,keeney1976decision,selten1991game,fudenberg1998theory,barany1987computing},
	Date-Added = {2011-05-20 14:21:47 +0200},
	Date-Modified = {2011-10-19 07:46:34 +0000},
	Keywords = {IRL},
	Pages = {35--42},
	Read = {1},
	Title = {Learning an agent's utility function by observing behavior},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAfQAAAAAAfQAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbBljaGFqZXdza2EyMDAxbGVhcm5pbmcucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXF1ypkHgAAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADKmOtgAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBiU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AGNoYWpld3NrYTIwMDFsZWFybmluZy5wZGYADgA0ABkAYwBoAGEAagBlAHcAcwBrAGEAMgAwADAAMQBsAGUAYQByAG4AaQBuAGcALgBwAGQAZgAPAAwABQBTAGwAYQBzAGgAEgBUVXNlcnMvZWRvdWFyZC9Eb2N1bWVudHMvTWllbnMvVHJhdmFpbC9UaGVzZS9CaWJsaW8vUGFwaWVycy9jaGFqZXdza2EyMDAxbGVhcm5pbmcucGRmABMAAS8AABUAAgAO//8AAIAF0hwdHh9YJGNsYXNzZXNaJGNsYXNzbmFtZaMfICFdTlNNdXRhYmxlRGF0YVZOU0RhdGFYTlNPYmplY3RfECFQYXBpZXJzL2NoYWpld3NrYTIwMDFsZWFybmluZy5wZGbSHB0kJaIlIVxOU0RpY3Rpb25hcnkSAAGGoF8QD05TS2V5ZWRBcmNoaXZlcgAIABEAFgAfACgAMgA1ADoAPABFAEsAUgBdAGUAbABvAHEAcwB2AHgAegB8AIYAkwCYAKACmAKaAp8CqAKzArcCxQLMAtUC+QL+AwEDDgMTAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAyU=}}


@inproceedings{levine2010feature,
	Author = {Levine, S. and Popovic, Z. and Koltun, V.},
	Booktitle = {Proc. NIPS},
	Date-Added = {2011-11-21 09:37:09 +0000},
	Date-Modified = {2011-11-21 09:37:21 +0000},
	Keywords = {Alire},
	Pages = {1342--1350},
	Title = {Feature construction for inverse reinforcement learning},
	Volume = {23},
	Year = {2010}}

@article{levine2011nonlinear,
	Author = {Levine, S. and Popovic, Z. and Koltun, V.},
	Cites1 = {dvijotham2010inverse,quinonero2005unifying,rasmussen2004gaussian,rasmussen2005gaussian,ziebart2010modeling,ziebart2008maximum},
	Cites2 = {abbeel2004apprenticeship},
	Cites3 = {deisenroth2009gaussian,engel2005reinforcement,levine2010feature,neu2007apprenticeship,ng2000algorithms,ramachandran2007bayesian,ratliff2006maximum,ratliff2007boosting,ratliff2009learning,syed2008game},
	Date-Added = {2011-11-21 09:33:18 +0000},
	Date-Modified = {2011-11-21 09:54:47 +0000},
	Journal = {Neural Information Processing Systems (NIPS)},
	Keywords = {IRL},
	Read = {1},
	Title = {Nonlinear Inverse Reinforcement Learning with Gaussian Processes},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAewAAAAAAewAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbBdsZXZpbmUyMDExbm9ubGluZWFyLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXGKyuFMgwAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADK4T5zAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBgU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AGxldmluZTIwMTFub25saW5lYXIucGRmAA4AMAAXAGwAZQB2AGkAbgBlADIAMAAxADEAbgBvAG4AbABpAG4AZQBhAHIALgBwAGQAZgAPAAwABQBTAGwAYQBzAGgAEgBSVXNlcnMvZWRvdWFyZC9Eb2N1bWVudHMvTWllbnMvVHJhdmFpbC9UaGVzZS9CaWJsaW8vUGFwaWVycy9sZXZpbmUyMDExbm9ubGluZWFyLnBkZgATAAEvAAAVAAIADv//AACABdIcHR4fWCRjbGFzc2VzWiRjbGFzc25hbWWjHyAhXU5TTXV0YWJsZURhdGFWTlNEYXRhWE5TT2JqZWN0XxAfUGFwaWVycy9sZXZpbmUyMDExbm9ubGluZWFyLnBkZtIcHSQloiUhXE5TRGljdGlvbmFyeRIAAYagXxAPTlNLZXllZEFyY2hpdmVyAAgAEQAWAB8AKAAyADUAOgA8AEUASwBSAF0AZQBsAG8AcQBzAHYAeAB6AHwAhgCTAJgAoAKQApIClwKgAqsCrwK9AsQCzQLvAvQC9wMEAwkAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADGw==}}


@inproceedings{qiao2011inverse,
	Annote = {Relire : Param{\'e}tr{\'e} ?},
	Author = {Qiao, Q. and Beling, P.A.},
	Booktitle = {American Control Conference (ACC), 2011},
	Cites1 = {ramachandran2007bayesian,chu2005preference,rasmussen2005gaussian},
	Cites3 = {ratliff2009inverse,ng2000algorithms,abbeel2004apprenticeship,syed2008apprenticeship,neu2007apprenticeship,syed2008game,dvijotham2010inverse,furnkranz2010preference},
	Date-Added = {2011-11-10 08:36:32 +0000},
	Date-Modified = {2011-11-18 09:36:17 +0000},
	Keywords = {IRL},
	Organization = {IEEE},
	Pages = {113--118},
	Read = {1},
	Title = {Inverse reinforcement learning with Gaussian process},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAdwAAAAAAdwAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbBNxaWFvMjAxMWludmVyc2UucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXGVyuFMgwAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADK4T5zAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBcU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AHFpYW8yMDExaW52ZXJzZS5wZGYADgAoABMAcQBpAGEAbwAyADAAMQAxAGkAbgB2AGUAcgBzAGUALgBwAGQAZgAPAAwABQBTAGwAYQBzAGgAEgBOVXNlcnMvZWRvdWFyZC9Eb2N1bWVudHMvTWllbnMvVHJhdmFpbC9UaGVzZS9CaWJsaW8vUGFwaWVycy9xaWFvMjAxMWludmVyc2UucGRmABMAAS8AABUAAgAO//8AAIAF0hwdHh9YJGNsYXNzZXNaJGNsYXNzbmFtZaMfICFdTlNNdXRhYmxlRGF0YVZOU0RhdGFYTlNPYmplY3RfEBtQYXBpZXJzL3FpYW8yMDExaW52ZXJzZS5wZGbSHB0kJaIlIVxOU0RpY3Rpb25hcnkSAAGGoF8QD05TS2V5ZWRBcmNoaXZlcgAIABEAFgAfACgAMgA1ADoAPABFAEsAUgBdAGUAbABvAHEAcwB2AHgAegB8AIYAkwCYAKACgAKCAocCkAKbAp8CrQK0Ar0C2wLgAuMC8AL1AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAwc=}}


@inproceedings{jin2010gaussian,
	Author = {Jin, Z.J. and Qian, H. and Zhu, M.L.},
	Booktitle = {International Conference on Machine Learning and Cybernetics (ICMLC)},
	Cites1 = {rasmussen2004gaussian,deisenroth2009gaussian},
	Cites3 = {abbeel2004apprenticeship,neu2007apprenticeship,neu2009training,ng2000algorithms,ratliff2006maximum,russell1998learning,syed2008apprenticeship,ziebart2008maximum,dearden1998bayesian,tipping2001sparse},
	Date-Added = {2011-09-23 07:51:49 +0000},
	Date-Modified = {2011-10-14 11:32:32 +0000},
	Keywords = {IRL},
	Organization = {IEEE},
	Pages = {225--230},
	Read = {1},
	Title = {Gaussian processes in inverse reinforcement learning},
	Volume = {1},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAdwAAAAAAdwAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbBNqaW4yMDEwZ2F1c3NpYW4ucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXGCypkHjAAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADKmOtsAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBcU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AGppbjIwMTBnYXVzc2lhbi5wZGYADgAoABMAagBpAG4AMgAwADEAMABnAGEAdQBzAHMAaQBhAG4ALgBwAGQAZgAPAAwABQBTAGwAYQBzAGgAEgBOVXNlcnMvZWRvdWFyZC9Eb2N1bWVudHMvTWllbnMvVHJhdmFpbC9UaGVzZS9CaWJsaW8vUGFwaWVycy9qaW4yMDEwZ2F1c3NpYW4ucGRmABMAAS8AABUAAgAO//8AAIAF0hwdHh9YJGNsYXNzZXNaJGNsYXNzbmFtZaMfICFdTlNNdXRhYmxlRGF0YVZOU0RhdGFYTlNPYmplY3RfEBtQYXBpZXJzL2ppbjIwMTBnYXVzc2lhbi5wZGbSHB0kJaIlIVxOU0RpY3Rpb25hcnkSAAGGoF8QD05TS2V5ZWRBcmNoaXZlcgAIABEAFgAfACgAMgA1ADoAPABFAEsAUgBdAGUAbABvAHEAcwB2AHgAegB8AIYAkwCYAKACgAKCAocCkAKbAp8CrQK0Ar0C2wLgAuMC8AL1AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAwc=}}


@article{boularias2011relative,
	Author = {Boularias, A. and Kober, J. and Peters},
	Cites1 = {ng2000algorithms,schaal1999imitation,abbeel2004apprenticeship,syed2008game,peters2010relative,dudik2006maximum},
	Cites2 = {atkeson1997locally,pomerleau1989alvinn},
	Cites3 = {ratliff2009learning,ratliff2006maximum,ramachandran2007bayesian,lopes2009active,neu2007apprenticeship,syed2008apprenticeship,abbeel2010autonomous},
	Date-Added = {2011-07-17 12:49:57 +0200},
	Date-Modified = {2011-10-21 08:25:29 +0000},
	Journal = {International Conference on Automated Planning and Scheduling (ICAPS)},
	Keywords = {IRL,Toto},
	Pages = {20--27},
	Publisher = {AAAI Press},
	Read = {1},
	Title = {Relative Entropy Inverse Reinforcement Learning},
	Volume = {15},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAfQAAAAAAfQAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbBlib3VsYXJpYXMyMDExcmVsYXRpdmUucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXFzypkHfwAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADKmOtfAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBiU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AGJvdWxhcmlhczIwMTFyZWxhdGl2ZS5wZGYADgA0ABkAYgBvAHUAbABhAHIAaQBhAHMAMgAwADEAMQByAGUAbABhAHQAaQB2AGUALgBwAGQAZgAPAAwABQBTAGwAYQBzAGgAEgBUVXNlcnMvZWRvdWFyZC9Eb2N1bWVudHMvTWllbnMvVHJhdmFpbC9UaGVzZS9CaWJsaW8vUGFwaWVycy9ib3VsYXJpYXMyMDExcmVsYXRpdmUucGRmABMAAS8AABUAAgAO//8AAIAF0hwdHh9YJGNsYXNzZXNaJGNsYXNzbmFtZaMfICFdTlNNdXRhYmxlRGF0YVZOU0RhdGFYTlNPYmplY3RfECFQYXBpZXJzL2JvdWxhcmlhczIwMTFyZWxhdGl2ZS5wZGbSHB0kJaIlIVxOU0RpY3Rpb25hcnkSAAGGoF8QD05TS2V5ZWRBcmNoaXZlcgAIABEAFgAfACgAMgA1ADoAPABFAEsAUgBdAGUAbABvAHEAcwB2AHgAegB8AIYAkwCYAKACmAKaAp8CqAKzArcCxQLMAtUC+QL+AwEDDgMTAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAyU=}}


@inproceedings{dvijotham2010inverse,
	Author = {Dvijotham, K. and Todorov, E.},
	Booktitle = {Proceedings of the Interntional Conference on Machine Learning},
	Date-Added = {2011-10-21 08:27:21 +0000},
	Date-Modified = {2011-11-22 15:16:14 +0000},
	Keywords = {Toto},
	Title = {Inverse Optimal Control with Linearly-Solvable MDPs},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAfIAAAAAAfIAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbBhkdmlqb3RoYW0yMDEwaW52ZXJzZS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXF9yuFMgwAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADK4T5zAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBhU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AGR2aWpvdGhhbTIwMTBpbnZlcnNlLnBkZgAADgAyABgAZAB2AGkAagBvAHQAaABhAG0AMgAwADEAMABpAG4AdgBlAHIAcwBlAC4AcABkAGYADwAMAAUAUwBsAGEAcwBoABIAU1VzZXJzL2Vkb3VhcmQvRG9jdW1lbnRzL01pZW5zL1RyYXZhaWwvVGhlc2UvQmlibGlvL1BhcGllcnMvZHZpam90aGFtMjAxMGludmVyc2UucGRmAAATAAEvAAAVAAIADv//AACABdIcHR4fWCRjbGFzc2VzWiRjbGFzc25hbWWjHyAhXU5TTXV0YWJsZURhdGFWTlNEYXRhWE5TT2JqZWN0XxAgUGFwaWVycy9kdmlqb3RoYW0yMDEwaW52ZXJzZS5wZGbSHB0kJaIlIVxOU0RpY3Rpb25hcnkSAAGGoF8QD05TS2V5ZWRBcmNoaXZlcgAIABEAFgAfACgAMgA1ADoAPABFAEsAUgBdAGUAbABvAHEAcwB2AHgAegB8AIYAkwCYAKAClgKYAp0CpgKxArUCwwLKAtMC9gL7Av4DCwMQAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAyI=}}


@article{syed2008game,
	Author = {Syed, U. and Schapire, R.E.},
	Cites1 = {abbeel2004apprenticeship,freund1999adaptive},
	Cites2 = {ratliff2006maximum},
	Cites3 = {kearns2002near,abbeel2005exploration},
	Comprehension = {1},
	Date-Added = {2010-09-09 11:33:28 +0200},
	Date-Modified = {2012-03-16 09:56:50 +0000},
	Journal = {Advances in neural information processing systems},
	Keywords = {IRL,Toto},
	Pages = {1449--1456},
	Read = {1},
	Title = {A game-theoretic approach to apprenticeship learning},
	Volume = {20},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAdIAAAAAAdIAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbBBzeWVkMjAwOGdhbWUucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXGkypkHjAAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADKmOtsAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBZU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AHN5ZWQyMDA4Z2FtZS5wZGYAAA4AIgAQAHMAeQBlAGQAMgAwADAAOABnAGEAbQBlAC4AcABkAGYADwAMAAUAUwBsAGEAcwBoABIAS1VzZXJzL2Vkb3VhcmQvRG9jdW1lbnRzL01pZW5zL1RyYXZhaWwvVGhlc2UvQmlibGlvL1BhcGllcnMvc3llZDIwMDhnYW1lLnBkZgAAEwABLwAAFQACAA7//wAAgAXSHB0eH1gkY2xhc3Nlc1okY2xhc3NuYW1lox8gIV1OU011dGFibGVEYXRhVk5TRGF0YVhOU09iamVjdF8QGFBhcGllcnMvc3llZDIwMDhnYW1lLnBkZtIcHSQloiUhXE5TRGljdGlvbmFyeRIAAYagXxAPTlNLZXllZEFyY2hpdmVyAAgAEQAWAB8AKAAyADUAOgA8AEUASwBSAF0AZQBsAG8AcQBzAHYAeAB6AHwAhgCTAJgAoAJ2AngCfQKGApEClQKjAqoCswLOAtMC1gLjAugAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC+g==}}



@article{ratliff2007boosting,
	Author = {Ratliff, N. and Bradley, D. and Bagnell, J.A. and Chestnutt, J.},
	Cites1 = {beygelzimer2005error,dietterich2004training,friedman2001greedy,mason1999functional,ratliff2006maximum},
	Cites2 = {yagi1999biped},
	Cites3 = {hassani1999mathematical,chestnutt2005footstep,tsochantaridis2006large,taskar2003max,taskar2005learning},
	Date-Added = {2010-09-03 10:37:47 +0200},
	Date-Modified = {2011-11-21 09:39:12 +0000},
	Journal = {Advances in Neural Information Processing Systems},
	Keywords = {IRL,Toto},
	Pages = {1153},
	Read = {1},
	Title = {Boosting structured prediction for imitation learning},
	Volume = {19},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAcwAAAAAAcwAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbA9SYXRsaWZmMjAwNy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXGYypkHfQAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADKmOtdAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBYU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AFJhdGxpZmYyMDA3LnBkZgAOACAADwBSAGEAdABsAGkAZgBmADIAMAAwADcALgBwAGQAZgAPAAwABQBTAGwAYQBzAGgAEgBKVXNlcnMvZWRvdWFyZC9Eb2N1bWVudHMvTWllbnMvVHJhdmFpbC9UaGVzZS9CaWJsaW8vUGFwaWVycy9SYXRsaWZmMjAwNy5wZGYAEwABLwAAFQACAA7//wAAgAXSHB0eH1gkY2xhc3Nlc1okY2xhc3NuYW1lox8gIV1OU011dGFibGVEYXRhVk5TRGF0YVhOU09iamVjdF8QF1BhcGllcnMvUmF0bGlmZjIwMDcucGRm0hwdJCWiJSFcTlNEaWN0aW9uYXJ5EgABhqBfEA9OU0tleWVkQXJjaGl2ZXIACAARABYAHwAoADIANQA6ADwARQBLAFIAXQBlAGwAbwBxAHMAdgB4AHoAfACGAJMAmACgAnACcgJ3AoACiwKPAp0CpAKtAscCzALPAtwC4QAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALz}}


@conference{ratliff2007imitation,
	Author = {Ratliff, N. and Bagnell, J.A. and Srinivasa, S.S.},
	Booktitle = {International Conference on Humanoid Robots},
	Cites1 = {ratliff2007boosting,bagnell2007exponentiated,taskar2005learning,ratliff2007online,saxena2006robotic,miller2003automatic},
	Cites3 = {vapnik1995nature,mason1999functional,friedman2001greedy,cesa2006prediction,hill2001convergence},
	Date-Added = {2011-03-28 14:54:12 +0200},
	Date-Modified = {2011-10-19 07:38:07 +0000},
	Keywords = {IRL},
	Organization = {IEEE},
	Pages = {392--397},
	Read = {1},
	Title = {Imitation learning for locomotion and manipulation},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAfIAAAAAAfIAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbBhyYXRsaWZmMjAwN2ltaXRhdGlvbi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXGZypkHlQAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADKmOt1AAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBhU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AHJhdGxpZmYyMDA3aW1pdGF0aW9uLnBkZgAADgAyABgAcgBhAHQAbABpAGYAZgAyADAAMAA3AGkAbQBpAHQAYQB0AGkAbwBuAC4AcABkAGYADwAMAAUAUwBsAGEAcwBoABIAU1VzZXJzL2Vkb3VhcmQvRG9jdW1lbnRzL01pZW5zL1RyYXZhaWwvVGhlc2UvQmlibGlvL1BhcGllcnMvcmF0bGlmZjIwMDdpbWl0YXRpb24ucGRmAAATAAEvAAAVAAIADv//AACABdIcHR4fWCRjbGFzc2VzWiRjbGFzc25hbWWjHyAhXU5TTXV0YWJsZURhdGFWTlNEYXRhWE5TT2JqZWN0XxAgUGFwaWVycy9yYXRsaWZmMjAwN2ltaXRhdGlvbi5wZGbSHB0kJaIlIVxOU0RpY3Rpb25hcnkSAAGGoF8QD05TS2V5ZWRBcmNoaXZlcgAIABEAFgAfACgAMgA1ADoAPABFAEsAUgBdAGUAbABvAHEAcwB2AHgAegB8AIYAkwCYAKAClgKYAp0CpgKxArUCwwLKAtMC9gL7Av4DCwMQAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAyI=}}


@article{lagoudakis2003least,
	Author = {Lagoudakis, M.G. and Parr, R.},
	Cites1 = {bradtke1996linear,howard1960dynamic,schweitzer1985generalized},
	Cites2 = {precup2001off,koller2000policy,watkins1989learning,lin1993reinforcement,rummery1994line,sutton1996generalization,ormoneit2002kernel,ng2000pegasus,baxter2001infinite,ng1999policysearch,sutton2000policy},
	Cites3 = {bertsekas1996neuro,barto1983neuronlike,sutton1984temporal,munos2003error,williams1994tight,sutton1998reinforcement,dempster1977simulation,nedic2003least,boyan2002technical,bradtke1993reinforcement},
	Comprehension = {1},
	Date-Added = {2010-11-30 14:51:51 +0100},
	Date-Modified = {2011-10-19 07:48:24 +0000},
	Issn = {1532-4435},
	Journal = {The Journal of Machine Learning Research},
	Keywords = {RL},
	Pages = {1107--1149},
	Publisher = {JMLR. org},
	Read = {1},
	Title = {Least-squares policy iteration},
	Volume = {4},
	Year = {2003},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAewAAAAAAewAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbBdMYWdvdWRha2lzMjAwM2xlYXN0LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXGGypkHewAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADKmOtbAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBgU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AExhZ291ZGFraXMyMDAzbGVhc3QucGRmAA4AMAAXAEwAYQBnAG8AdQBkAGEAawBpAHMAMgAwADAAMwBsAGUAYQBzAHQALgBwAGQAZgAPAAwABQBTAGwAYQBzAGgAEgBSVXNlcnMvZWRvdWFyZC9Eb2N1bWVudHMvTWllbnMvVHJhdmFpbC9UaGVzZS9CaWJsaW8vUGFwaWVycy9MYWdvdWRha2lzMjAwM2xlYXN0LnBkZgATAAEvAAAVAAIADv//AACABdIcHR4fWCRjbGFzc2VzWiRjbGFzc25hbWWjHyAhXU5TTXV0YWJsZURhdGFWTlNEYXRhWE5TT2JqZWN0XxAfUGFwaWVycy9MYWdvdWRha2lzMjAwM2xlYXN0LnBkZtIcHSQloiUhXE5TRGljdGlvbmFyeRIAAYagXxAPTlNLZXllZEFyY2hpdmVyAAgAEQAWAB8AKAAyADUAOgA8AEUASwBSAF0AZQBsAG8AcQBzAHYAeAB6AHwAhgCTAJgAoAKQApIClwKgAqsCrwK9AsQCzQLvAvQC9wMEAwkAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAADGw==}}

@conference{ng1999policy,
	Annote = {Cit{\'e} par \cite{abbeel2004apprenticeship} :
	"The reward function is often manually tweaked until the desired behavior is obtained."
Cit{\'e} par \cite{ng2000algorithms} :
	"Can we design IRL algorithm that design easy reward functions ?"},
	Author = {Ng, A.Y. and Harada, D. and Russell, S.},
	Booktitle = {International Conference on Machine Learning (ICML)},
	Cites3 = {von1944theory,russell1998learning,rust1994people,dorigo1994robot,mataric1994reward,saksida1997shaping,randlov1998learning,baird1994reinforcement,bertsekas1996neuro,sutton1998reinforcement,bertsekas2001dynamic,hernandez1989adaptive,bertsekas1978stochastic},
	Date-Added = {2010-09-01 15:48:32 +0200},
	Date-Modified = {2012-03-16 09:52:40 +0000},
	Keywords = {RewardShaping,Toto},
	Pages = {278--287},
	Read = {1},
	Title = {Policy invariance under reward transformations: Theory and application to reward shaping},
	Year = {1999},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RFFpOUy5vYmplY3RzV05TLmtleXNWJGNsYXNzog8QgASABqISE4ACgAOAB1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgNGRpXTlMuZGF0YU8RAdIAAAAAAdIAAgAABVNsYXNoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMtYC1RIKwAAAAlxbBBuZzE5OTlwb2xpY3kucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACXGRypkHhgAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHUGFwaWVycwAAEAAIAADLV/1EAAAAEQAIAADKmOtmAAAAAQAgAAlxbAAJbFQACWxTAAliqAAJVE4ACUKqAAkx6gAJMecAAgBZU2xhc2g6VXNlcnM6AGVkb3VhcmQ6AERvY3VtZW50czoATWllbnM6AFRyYXZhaWw6AFRoZXNlOgBCaWJsaW86AFBhcGllcnM6AG5nMTk5OXBvbGljeS5wZGYAAA4AIgAQAG4AZwAxADkAOQA5AHAAbwBsAGkAYwB5AC4AcABkAGYADwAMAAUAUwBsAGEAcwBoABIAS1VzZXJzL2Vkb3VhcmQvRG9jdW1lbnRzL01pZW5zL1RyYXZhaWwvVGhlc2UvQmlibGlvL1BhcGllcnMvbmcxOTk5cG9saWN5LnBkZgAAEwABLwAAFQACAA7//wAAgAXSHB0eH1gkY2xhc3Nlc1okY2xhc3NuYW1lox8gIV1OU011dGFibGVEYXRhVk5TRGF0YVhOU09iamVjdF8QGFBhcGllcnMvbmcxOTk5cG9saWN5LnBkZtIcHSQloiUhXE5TRGljdGlvbmFyeRIAAYagXxAPTlNLZXllZEFyY2hpdmVyAAgAEQAWAB8AKAAyADUAOgA8AEUASwBSAF0AZQBsAG8AcQBzAHYAeAB6AHwAhgCTAJgAoAJ2AngCfQKGApEClQKjAqoCswLOAtMC1gLjAugAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC+g==}}


@article{lopes2009active,
	Author = {Lopes, M. and Melo, F. and Montesano, L.},
	Date-Added = {2011-10-13 08:51:24 +0000},
	Date-Modified = {2011-10-14 06:50:16 +0000},
	Journal = {Machine Learning and Knowledge Discovery in Databases},
	Keywords = {Alire},
	Pages = {31--46},
	Publisher = {Springer},
	Title = {Active learning for reward estimation in inverse reinforcement learning},
	Year = {2009}}


