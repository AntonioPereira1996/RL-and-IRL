{
 "metadata": {
  "name": "Exp5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Mountain Car\n",
      "from stuff import *\n",
      "from pylab import *\n",
      "from random import *\n",
      "import pickle\n",
      "import numpy\n",
      "from rl import *\n",
      "import sys\n",
      "\n",
      "NB_SAMPLES=100\n",
      "#NB_SAMPLES=int(sys.argv[1])\n",
      "RAND_STRING=str(int(rand()*10000000000))\n",
      "\n",
      "\n",
      "ACTION_SPACE=[-1,0,1]\n",
      "\n",
      "\n",
      "\n",
      "def mountain_car_next_state(state,action):\n",
      "    position,speed=state\n",
      "    next_speed = squeeze(speed+action*0.001+cos(3*position)*(-0.0025))\n",
      "    next_position = squeeze(position+next_speed)\n",
      "    if not -0.07 <= next_speed <= 0.07:\n",
      "        next_speed = sign(next_speed)*0.07\n",
      "    if not -1.2 <= next_position <= 0.6:\n",
      "        next_speed=0.\n",
      "        next_position = -1.2 if next_position < -1.2 else 0.6\n",
      "    return array([next_position,next_speed])\n",
      "\n",
      "def mountain_car_uniform_state():\n",
      "    return array([numpy.random.uniform(low=-1.2,high=0.6),numpy.random.uniform(low=-0.07,high=0.07)])\n",
      "\n",
      "mountain_car_mu_position, mountain_car_mu_speed = meshgrid(linspace(-1.2,0.6,7),linspace(-0.07,0.07,7))\n",
      "\n",
      "mountain_car_sigma_position = 2*pow((0.6+1.2)/10.,2)\n",
      "mountain_car_sigma_speed = 2*pow((0.07+0.07)/10.,2)\n",
      "\n",
      "def mountain_car_single_psi(state):\n",
      "    position,speed=state\n",
      "    psi=[]\n",
      "    for mu in zip_stack(mountain_car_mu_position, mountain_car_mu_speed).reshape(7*7,2):\n",
      "        psi.append(exp( -pow(position-mu[0],2)/mountain_car_sigma_position \n",
      "                        -pow(speed-mu[1],2)/mountain_car_sigma_speed))\n",
      "    psi.append(1.)\n",
      "    return array(psi).reshape((7*7+1,1))\n",
      "\n",
      "mountain_car_psi= non_scalar_vectorize(mountain_car_single_psi,(2,),(50,1))\n",
      "\n",
      "def mountain_car_single_phi(sa):\n",
      "    state=sa[:2]\n",
      "    index_action = int(sa[-1])+1\n",
      "    answer=zeros(((7*7+1)*3,1))\n",
      "    answer[index_action*(7*7+1):index_action*(7*7+1)+7*7+1] = mountain_car_psi(state)\n",
      "    return answer\n",
      "\n",
      "mountain_car_phi= non_scalar_vectorize(mountain_car_single_phi,(3,),(150,1))\n",
      "\n",
      "def mountain_car_reward(sas):\n",
      "    position=sas[0]\n",
      "    return 1 if position > 0.5 else 0\n",
      "\n",
      "def mountain_car_episode_length(initial_position,initial_speed,policy):\n",
      "    answer = 0\n",
      "    reward = 0.\n",
      "    state = array([initial_position,initial_speed])\n",
      "    while answer < 300 and reward == 0. :\n",
      "        action = policy(state)\n",
      "        next_state = mountain_car_next_state(state,action)\n",
      "        reward = mountain_car_reward(hstack([state, action, next_state]))\n",
      "        state=next_state\n",
      "        answer+=1\n",
      "    return answer\n",
      "\n",
      "def mountain_car_episode_vlength(policy):\n",
      "    return vectorize(lambda p,s:mountain_car_episode_length(p,s,policy))\n",
      "\n",
      "\n",
      "def mountain_car_training_data(freward=mountain_car_reward,traj_length=5,nb_traj=1000):\n",
      "    traj = []\n",
      "    random_policy = lambda s:choice(ACTION_SPACE)\n",
      "    for i in range(0,nb_traj):\n",
      "        state = mountain_car_uniform_state()\n",
      "        reward=0\n",
      "        t=0\n",
      "        while t < traj_length and reward == 0:\n",
      "            t+=1\n",
      "            action = random_policy(state)\n",
      "            next_state = mountain_car_next_state(state, action)\n",
      "            reward = freward(hstack([state, action, next_state]))\n",
      "            traj.append(hstack([state, action, next_state, reward]))\n",
      "            state=next_state\n",
      "    return array(traj)\n",
      "\n",
      "def mountain_car_manual_policy(state):\n",
      "    position,speed = state\n",
      "    return -1. if speed <=0 else 1.\n",
      "\n",
      "def mountain_car_interesting_state():\n",
      "    position = numpy.random.uniform(low=-1.2,high=-0.9)\n",
      "    speed = numpy.random.uniform(low=-0.07,high=0)\n",
      "    return array([position,speed])\n",
      "\n",
      "def mountain_car_IRL_traj():\n",
      "    traj = []\n",
      "    state = mountain_car_interesting_state()\n",
      "    reward = 0\n",
      "    while reward == 0:\n",
      "        action = mountain_car_manual_policy(state)\n",
      "        next_state = mountain_car_next_state(state, action)\n",
      "        next_action = mountain_car_manual_policy(next_state)\n",
      "        reward = mountain_car_reward(hstack([state, action, next_state]))\n",
      "        traj.append(hstack([state, action, next_state, next_action, reward]))\n",
      "        state=next_state\n",
      "    return array(traj)\n",
      "\n",
      "def mountain_car_IRL_data(nbsamples):\n",
      "    data = mountain_car_IRL_traj()\n",
      "    while len(data) < nbsamples:\n",
      "        data = vstack([data,mountain_car_IRL_traj()])\n",
      "    return data[:nbsamples]\n",
      "\n",
      "TRAJS = mountain_car_IRL_data(NB_SAMPLES)\n",
      "while all(TRAJS[:,2]==-1):\n",
      "    print \"Resampling manual policy until we get 2 actions\"\n",
      "    TRAJS = mountain_car_IRL_data(NB_SAMPLES)\n",
      "\n",
      "psi=mountain_car_psi\n",
      "phi=mountain_car_phi\n",
      "s=TRAJS[:,:2]\n",
      "a=TRAJS[:,2]\n",
      "#Classification\n",
      "from sklearn import svm\n",
      "clf = svm.SVC(C=1, probability=True, gamma=1/(2*pow(0.03,2)))\n",
      "clf.fit(s, a)\n",
      "def clf_predict(state):\n",
      "    try:\n",
      "        return clf.predict(squeeze(state))\n",
      "    except ValueError:\n",
      "        return 1.\n",
      "vpredict = non_scalar_vectorize( clf_predict, (2,), (1,1) )\n",
      "pi_c = lambda state: vpredict(state).reshape(state.shape[:-1]+(1,))\n",
      "def clf_score(sa):\n",
      "    #try:\n",
      "    action = sa[-1]\n",
      "    index=0\n",
      "    if action == -1.:\n",
      "        index = 0\n",
      "    elif action == 1.:\n",
      "        index = 1\n",
      "    else:\n",
      "        return 0\n",
      "    return squeeze(clf.predict_proba(squeeze(sa[:2])))[sa[index]]\n",
      "vscore = non_scalar_vectorize( clf_score,(3,),(1,1) )\n",
      "q = lambda sa: vscore(sa).reshape(sa.shape[:-1])\n",
      "#Donn\u00e9es pour la regression\n",
      "column_shape = (len(TRAJS),1)\n",
      "s = TRAJS[:,0:2]\n",
      "a = TRAJS[:,2].reshape(column_shape)\n",
      "sa = TRAJS[:,0:3]\n",
      "s_dash = TRAJS[:,3:5]\n",
      "a_dash = pi_c(s_dash).reshape(column_shape)\n",
      "sa_dash = hstack([s_dash,a_dash])\n",
      "hat_r = (q(sa)-GAMMA*q(sa_dash)).reshape(column_shape)\n",
      "r_min = min(hat_r)-1.*ones(column_shape)\n",
      "\n",
      "##Avec l'heuristique : \n",
      "regression_input_matrices = [hstack([s,action*ones(column_shape)]) for action in ACTION_SPACE] \n",
      "def add_output_column( reg_mat ):\n",
      "    actions = reg_mat[:,-1].reshape(column_shape)\n",
      "    hat_r_bool_table = array(actions==a)\n",
      "    r_min_bool_table = array(hat_r_bool_table==False) #\"not hat_r_bool_table\" does not work as I expected\n",
      "    output_column = hat_r_bool_table*hat_r+r_min_bool_table*r_min\n",
      "    return hstack([reg_mat,output_column])\n",
      "regression_matrix = vstack(map(add_output_column,regression_input_matrices))\n",
      "#R\u00e9gression\n",
      "from sklearn.svm import SVR\n",
      "y = regression_matrix[:,-1]\n",
      "X = regression_matrix[:,:-1]\n",
      "reg = SVR(C=1.0, epsilon=0.2, gamma=1/(2*pow(0.03,2)))\n",
      "reg.fit(X, y)\n",
      "CSI_reward = lambda sas:reg.predict(sas[:3])[0]\n",
      "vCSI_reward = non_scalar_vectorize( CSI_reward, (5,),(1,1) )\n",
      "data = genfromtxt(\"mountain_car_batch_data.mat\")\n",
      "data[:,5] = squeeze(vCSI_reward(data[:,:5]))\n",
      "policy_CSI,omega_CSI = lspi( data, s_dim=2,a_dim=1, A=ACTION_SPACE, phi=mountain_car_phi, phi_dim=150, iterations_max=20 )\n",
      "def mountain_car_testing_state():\n",
      "    position = numpy.random.uniform(low=-1.2,high=0.5)\n",
      "    speed = numpy.random.uniform(low=-0.07,high=0.07)\n",
      "    return array([position,speed])\n",
      "\n",
      "def mountain_car_mean_performance(policy):\n",
      "    return mean([mountain_car_episode_length(state[0],state[1],policy) for state in [mountain_car_testing_state() for i in range(0,1)]])\n",
      "print \"Samples : \"+str(NB_SAMPLES)\n",
      "print \"CSI, classif : \"\n",
      "print mountain_car_mean_performance(policy_CSI),mountain_car_mean_performance(pi_c)\n",
      "savetxt(\"data/CSI_omega_\"+str(NB_SAMPLES)+\"_\"+RAND_STRING+\".mat\",omega_CSI)\n",
      "with open('data/Classif_'+str(NB_SAMPLES)+\"_\"+RAND_STRING+\".obj\", 'wb') as output:\n",
      "    pickle.dump(clf, output, pickle.HIGHEST_PROTOCOL)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LSPI, iter :1, diff : 45.6662590988\n",
        "LSPI, iter :2, diff : 27.5186891221"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :3, diff : 3.60991340925"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :4, diff : 0.212372455152"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :5, diff : 0.00136958304566"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Samples : 100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "CSI, classif : \n",
        "66.18"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 110.04\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "psi=mountain_car_psi\n",
      "phi=mountain_car_phi\n",
      "s=TRAJS[:,:2]\n",
      "a=TRAJS[:,2]\n",
      "\n",
      "s_dash=TRAJS[:,3:5]\n",
      "a_dash=TRAJS[:,5]\n",
      "sa=TRAJS[:,:3]\n",
      "sa_dash=TRAJS[:,3:6]\n",
      "\n",
      "##SCIRL\n",
      "#Precomputing mu with LSTDmu and heuristics\n",
      "A = zeros((150,150))\n",
      "b = zeros((150,50))\n",
      "phi_t = phi(sa)\n",
      "phi_t_dash = phi(sa_dash)\n",
      "psi_t = psi(s)\n",
      "for phi_t,phi_t_dash,psi_t in zip(phi_t,phi_t_dash,psi_t):\n",
      "    A = A + dot(phi_t,\n",
      "            (phi_t - GAMMA*phi_t_dash).transpose())\n",
      "    b = b + dot(phi_t,psi_t.transpose())\n",
      "omega_lstd_mu = dot(inv(A+0.1*identity(150)),b)\n",
      "phi_t.shape, phi_t_dash.shape, psi_t.shape\n",
      "feature_expectations = {}\n",
      "for state,action in zip(s,a):\n",
      "    state_action = hstack([state,action])\n",
      "    mu = dot(omega_lstd_mu.transpose(),phi(state_action))\n",
      "    feature_expectations[str(state_action)] = mu\n",
      "    for other_action in [a for a in ACTION_SPACE if a != action]:\n",
      "        state_action=hstack([state,other_action])\n",
      "        feature_expectations[str(state_action)]=GAMMA*mu\n",
      "        \n",
      "        \n",
      "#Precomputing mu with MC and heuristics\n",
      "feature_expectations_MC = {}\n",
      "for start_index in range(0,len(TRAJS)):\n",
      "    end_index = (i for i in range(start_index,len(TRAJS)) if TRAJS[i,6] == 1 or i==len(TRAJS)-1).next()\n",
      "    #print \"start_index : \"+str(start_index)+\" end_index : \"+str(end_index)\n",
      "    data_MC=TRAJS[start_index:end_index+1,:3]\n",
      "    GAMMAS = range(0,len(data_MC))\n",
      "    GAMMAS = array(map( lambda x: pow(GAMMA,x), GAMMAS))\n",
      "    state_action = data_MC[0,:3]\n",
      "    state = data_MC[0,:2]\n",
      "    action = data_MC[0,2]\n",
      "    mu = None\n",
      "    if len(data_MC) > 1:\n",
      "        mu = dot( GAMMAS,squeeze(psi(data_MC[:,:2])))\n",
      "    else:\n",
      "        mu = squeeze(psi(squeeze(data_MC[:,:2])))\n",
      "    feature_expectations_MC[str(state_action)] = mu\n",
      "    for other_action in [a for a in ACTION_SPACE if a != action]:\n",
      "        state_action=hstack([state,other_action])\n",
      "        feature_expectations_MC[str(state_action)]=GAMMA*mu\n",
      "        \n",
      "\n",
      "#Structured Classifier\n",
      "class GradientDescent(object):\n",
      "    \n",
      "   def alpha( self, t ):\n",
      "      raise NotImplementedError, \"Cannot call abstract method\"\n",
      "\n",
      "   theta_0=None\n",
      "   Threshold=None\n",
      "   T = -1\n",
      "   sign = None\n",
      "        \n",
      "   def run( self, f_grad, f_proj=None, b_norm=False ): #grad is a function of theta\n",
      "      theta = self.theta_0.copy()\n",
      "      best_theta = theta.copy()\n",
      "      best_norm = float(\"inf\")\n",
      "      best_iter = 0\n",
      "      t=0\n",
      "      while True:#Do...while loop\n",
      "         t+=1\n",
      "         DeltaTheta = f_grad( theta )\n",
      "         current_norm = norm( DeltaTheta )\n",
      "         if b_norm and  current_norm > 0.:\n",
      "             DeltaTheta /= norm( DeltaTheta )\n",
      "         theta = theta + self.sign * self.alpha( t )*DeltaTheta\n",
      "         if f_proj:\n",
      "             theta = f_proj( theta )\n",
      "         print \"Norme du gradient : \"+str(current_norm)+\", pas : \"+str(self.alpha(t))+\", iteration : \"+str(t)\n",
      "\n",
      "         if current_norm < best_norm:\n",
      "             best_norm = current_norm\n",
      "             best_theta = theta.copy()\n",
      "             best_iter = t\n",
      "         if current_norm < self.Threshold or (self.T != -1 and t >= self.T):\n",
      "             break\n",
      "\n",
      "      print \"Gradient de norme : \"+str(best_norm)+\", a l'iteration : \"+str(best_iter)\n",
      "      return best_theta\n",
      "\n",
      "\n",
      "class StructuredClassifier(GradientDescent):\n",
      "    sign=-1.\n",
      "    Threshold=0.1 #Sensible default\n",
      "    T=40 #Sensible default\n",
      "    phi=None\n",
      "    phi_xy=None\n",
      "    inputs=None\n",
      "    labels=None\n",
      "    label_set=None\n",
      "    dic_data={}\n",
      "    x_dim=None\n",
      "    \n",
      "    def alpha(self, t):\n",
      "        return 3./(t+1)#Sensible default\n",
      "    \n",
      "    def __init__(self, data, x_dim, phi, phi_dim, Y):\n",
      "        self.x_dim=x_dim\n",
      "        self.inputs = data[:,:-1]\n",
      "        shape = list(data.shape)\n",
      "        shape[-1] = 1\n",
      "        self.labels = data[:,-1].reshape(shape)\n",
      "        self.phi=phi\n",
      "        self.label_set = Y\n",
      "        self.theta_0 = zeros((phi_dim,1))\n",
      "        self.phi_xy = self.phi(data)\n",
      "        for x,y in zip(self.inputs,self.labels):\n",
      "            self.dic_data[str(x)] = y\n",
      "        print self.inputs.shape\n",
      "    \n",
      "    def structure(self, xy):\n",
      "        return 0. if xy[-1] == self.dic_data[str(xy[:-1])] else 1.\n",
      "        \n",
      "    def structured_decision(self, theta):\n",
      "        def decision( x ):\n",
      "            score = lambda xy: dot(theta.transpose(),self.phi(xy)) + self.structure(xy)\n",
      "            input_label_couples = [hstack([x,y]) for y in self.label_set]\n",
      "            best_label = argmax(input_label_couples, score)[-1]\n",
      "            return best_label\n",
      "        vdecision = non_scalar_vectorize(decision, (self.x_dim,), (1,1))\n",
      "        return lambda x: vdecision(x).reshape(x.shape[:-1]+(1,))\n",
      "    \n",
      "    def gradient(self, theta):\n",
      "        classif_rule = self.structured_decision(theta)\n",
      "        y_star = classif_rule(self.inputs)\n",
      "        #print \"Gradient : \"+str(y_star)\n",
      "        #print str(self.labels)\n",
      "        phi_star = self.phi(hstack([self.inputs,y_star]))\n",
      "        return mean(phi_star-self.phi_xy,axis=0)\n",
      "    \n",
      "    def run(self):\n",
      "        f_grad = lambda theta: self.gradient(theta)\n",
      "        theta = super(StructuredClassifier,self).run( f_grad, b_norm=True)\n",
      "        classif_rule = greedy_policy(theta,self.phi,self.label_set)\n",
      "        return classif_rule,theta\n",
      "\n",
      "#Version LSTDmu    \n",
      "single_mu = lambda sa:feature_expectations[str(sa)]\n",
      "mu_E = non_scalar_vectorize(single_mu, (3,), (50,1))\n",
      "SCIRL = StructuredClassifier(sa, 2, mu_E, 50, ACTION_SPACE)\n",
      "void,theta_SCIRL = SCIRL.run()\n",
      "#Evaluation de SCIRL\n",
      "SCIRL_reward = lambda sas:dot(theta_SCIRL.transpose(),psi(sas[:2]))[0]\n",
      "vSCIRL_reward = non_scalar_vectorize( SCIRL_reward, (5,),(1,1) )\n",
      "data = genfromtxt(\"mountain_car_batch_data.mat\")\n",
      "data[:,5] = squeeze(vSCIRL_reward(data[:,:5]))\n",
      "policy_SCIRL,omega_SCIRL = lspi( data, s_dim=2,a_dim=1, A=ACTION_SPACE, phi=mountain_car_phi, phi_dim=150, iterations_max=20 )#None,zeros((75,1))#\n",
      "savetxt(\"data/SCIRL_omega_\"+str(NB_SAMPLES)+\"_\"+RAND_STRING+\".mat\",omega_SCIRL)\n",
      "#Version MC_mu\n",
      "single_mu = lambda sa:feature_expectations_MC[str(sa)]\n",
      "mu_E = non_scalar_vectorize(single_mu, (3,), (50,1))\n",
      "SCIRL_MC = StructuredClassifier(sa, 2, mu_E, 50, ACTION_SPACE)\n",
      "void,theta_SCIRL_MC = SCIRL_MC.run()\n",
      "#Evaluation de SCIRL\n",
      "SCIRL_reward = lambda sas:dot(theta_SCIRL_MC.transpose(),psi(sas[:2]))[0]\n",
      "vSCIRL_reward = non_scalar_vectorize( SCIRL_reward, (5,),(1,1) )\n",
      "data = genfromtxt(\"mountain_car_batch_data.mat\")\n",
      "data[:,5] = squeeze(vSCIRL_reward(data[:,:5]))\n",
      "policy_SCIRL_MC,omega_SCIRL_MC = lspi( data, s_dim=2,a_dim=1, A=ACTION_SPACE, phi=mountain_car_phi, phi_dim=150, iterations_max=20 )#None,zeros((75,1))#\n",
      "savetxt(\"data/SCIRLMC_omega_\"+str(NB_SAMPLES)+\"_\"+RAND_STRING+\".mat\",omega_SCIRL_MC)\n",
      "print \"SCIRL, SCIRL MC : \"\n",
      "print mountain_car_mean_performance(policy_SCIRL),mountain_car_mean_performance(policy_SCIRL_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(100, 2)\n",
        "Norme du gradient : 1.08536433704, pas : 1.5, iteration : 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.0, pas : 1.0, iteration : 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Gradient de norme : 0.0, a l'iteration : 2\n",
        "LSPI, iter :1, diff : 27.4951724819"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :2, diff : 7.38683218588"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :3, diff : 1.0376242831"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :4, diff : 0.0533512634972"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :5, diff : 0.00118852268912"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(100, 2)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.925141691549, pas : 1.5, iteration : 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.0812352538071, pas : 1.0, iteration : 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Gradient de norme : 0.0812352538071, a l'iteration : 2\n",
        "LSPI, iter :1, diff : 44.8120705439"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :2, diff : 16.9197434735"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :3, diff : 1.72552247835"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :4, diff : 0.078728634182"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :5, diff : 0.000455398529959"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "SCIRL, SCIRL MC : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "63.64"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 57.08\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "GAMMA = 0.99\n",
      "\n",
      "def end_of_episode(data,i):\n",
      "    try:\n",
      "        if all(data[i,3:5] == data[i+1,:2]):\n",
      "            return False\n",
      "        else:\n",
      "            return True\n",
      "    except:\n",
      "        return True\n",
      "\n",
      "#Relative Entropy\n",
      "class GradientDescent(object):\n",
      "   def alpha( self, t ):\n",
      "      raise NotImplementedError, \"Cannot call abstract method\"\n",
      "\n",
      "   theta_0=None\n",
      "   Threshold=None\n",
      "   T = -1\n",
      "   sign = None\n",
      "        \n",
      "   def run( self, f_grad, f_proj=None, b_norm=False, b_best=True ): #grad is a function of theta\n",
      "      theta = self.theta_0.copy()\n",
      "      best_theta = theta.copy()\n",
      "      best_norm = float(\"inf\")\n",
      "      best_iter = 0\n",
      "      t=0\n",
      "      while True:#Do...while loop\n",
      "         t+=1\n",
      "         DeltaTheta = f_grad( theta )\n",
      "         current_norm = norm( DeltaTheta )\n",
      "         if b_norm and  current_norm > 0.:\n",
      "             DeltaTheta /= norm( DeltaTheta )\n",
      "         theta = theta + self.sign * self.alpha( t )*DeltaTheta\n",
      "         if f_proj:\n",
      "             theta = f_proj( theta )\n",
      "         print \"Norme du gradient : \"+str(current_norm)+\", pas : \"+str(self.alpha(t))+\", iteration : \"+str(t)\n",
      "\n",
      "         if current_norm < best_norm or not b_best:\n",
      "             best_norm = current_norm\n",
      "             best_theta = theta.copy()\n",
      "             best_iter = t\n",
      "         if current_norm < self.Threshold or (self.T != -1 and t >= self.T):\n",
      "             break\n",
      "\n",
      "      print \"Gradient de norme : \"+str(best_norm)+\", a l'iteration : \"+str(best_iter)\n",
      "      return best_theta\n",
      "                            \n",
      "class RelativeEntropy(GradientDescent):\n",
      "    sign=+1.\n",
      "    Threshold=0.01 #Sensible default\n",
      "    T=50 #Sensible default\n",
      "    Epsilon = 0.05 #RelEnt parameter, sensible default\n",
      "\n",
      "    def alpha(self, t):\n",
      "        return 1./(t+1)#Sensible default\n",
      "    \n",
      "    def __init__(self, mu_E, mus):\n",
      "        self.theta_0 = zeros(mu_E.shape)\n",
      "        self.Mu_E = mu_E\n",
      "        self.Mus = mus\n",
      "    \n",
      "    def gradient(self, theta):\n",
      "        numerator = 0\n",
      "        denominator = 0\n",
      "        for mu in self.Mus:\n",
      "            c = exp(dot(theta.transpose(),mu))\n",
      "            numerator += c*mu\n",
      "            denominator += c\n",
      "        assert denominator != 0,\"A sum of exp(...) is null, some black magic happened here.\"\n",
      "        return self.Mu_E - numerator/denominator - sign(theta)*self.Epsilon\n",
      "    \n",
      "    def run(self):\n",
      "        f_grad = lambda theta: self.gradient(theta)\n",
      "        theta = super(RelativeEntropy,self).run( f_grad, b_norm=True, b_best=False)\n",
      "        return theta\n",
      "\n",
      "    \n",
      "data_r = genfromtxt(\"mountain_car_batch_data.mat\")\n",
      "#data_r = genfromtxt(\"mountain_car_RE_trajs.mat\")\n",
      "\n",
      "#Computing the feature expectations\n",
      "t=0.\n",
      "Mu_E = zeros(((7*7+1)*3,1))\n",
      "for i in range(0,len(TRAJS)):\n",
      "    Mu_E += pow(GAMMA,t)*mountain_car_phi(TRAJS[i,:3])\n",
      "    if end_of_episode(TRAJS,i):\n",
      "        t=0.\n",
      "    else:\n",
      "        t+=1.\n",
      "Mu_E /= float(len(TRAJS))\n",
      "\n",
      "Mus=[]\n",
      "mu = zeros(((7*7+1)*3,1))\n",
      "t=0.\n",
      "for i in range(0,len(data_r)):\n",
      "    mu += pow(GAMMA,t)*mountain_car_phi(data_r[i,:3])\n",
      "    if end_of_episode(data_r,i):\n",
      "        mu /= t+1.\n",
      "        Mus.append(mu)\n",
      "        t=0.\n",
      "        mu = zeros(((7*7+1)*3,1))\n",
      "    else:\n",
      "        t += 1.\n",
      "        \n",
      "Mus.append(Mu_E)\n",
      "\n",
      "RE = RelativeEntropy(Mu_E, Mus)\n",
      "theta_RE = RE.run()\n",
      "def RE_reward(sas):\n",
      "    sa = sas[:3]\n",
      "    return squeeze(dot(theta_RE.transpose(),mountain_car_phi(sa)))\n",
      "vRE_reward = non_scalar_vectorize( RE_reward, (5,),(1,1) )\n",
      "data = genfromtxt(\"mountain_car_batch_data.mat\")\n",
      "data[:,5] = squeeze(vRE_reward(data[:,:5]))\n",
      "policy_RE,omega_RE = lspi( data, s_dim=2,a_dim=1, A=ACTION_SPACE, phi=mountain_car_phi, phi_dim=150, iterations_max=20 )\n",
      "savetxt(\"data/RE_omega_\"+str(NB_SAMPLES)+\"_\"+RAND_STRING+\".mat\",omega_RE)\n",
      "print \"RE: \"\n",
      "print mountain_car_mean_performance(policy_RE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Norme du gradient : 0.567920133558, pas : 0.5, iteration : 1\n",
        "Norme du gradient : 0.553693048109, pas : 0.333333333333, iteration : 2\n",
        "Norme du gradient : 0.747250345791, pas : 0.25, iteration : 3\n",
        "Norme du gradient : 0.626121152766, pas : 0.2, iteration : 4\n",
        "Norme du gradient : 0.611443839436, pas : 0.166666666667, iteration : 5\n",
        "Norme du gradient : 0.611832024377, pas : 0.142857142857, iteration : 6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.683447948236, pas : 0.125, iteration : 7\n",
        "Norme du gradient : 0.589492434325, pas : 0.111111111111, iteration : 8\n",
        "Norme du gradient : 0.620921484565, pas : 0.1, iteration : 9\n",
        "Norme du gradient : 0.643226047825, pas : 0.0909090909091, iteration : 10\n",
        "Norme du gradient : 0.603097219793, pas : 0.0833333333333, iteration : 11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.623082576872, pas : 0.0769230769231, iteration : 12\n",
        "Norme du gradient : 0.628839314559, pas : 0.0714285714286, iteration : 13\n",
        "Norme du gradient : 0.61534777812, pas : 0.0666666666667, iteration : 14\n",
        "Norme du gradient : 0.615870352537, pas : 0.0625, iteration : 15\n",
        "Norme du gradient : 0.628957672159, pas : 0.0588235294118, iteration : 16"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.620402384277, pas : 0.0555555555556, iteration : 17\n",
        "Norme du gradient : 0.603944140229, pas : 0.0526315789474, iteration : 18\n",
        "Norme du gradient : 0.616036484427, pas : 0.05, iteration : 19\n",
        "Norme du gradient : 0.624498611367, pas : 0.047619047619, iteration : 20\n",
        "Norme du gradient : 0.605652581104, pas : 0.0454545454545, iteration : 21"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.615805849905, pas : 0.0434782608696, iteration : 22\n",
        "Norme du gradient : 0.613578714929, pas : 0.0416666666667, iteration : 23\n",
        "Norme du gradient : 0.636708710349, pas : 0.04, iteration : 24\n",
        "Norme du gradient : 0.576601831952, pas : 0.0384615384615, iteration : 25\n",
        "Norme du gradient : 0.62923937806, pas : 0.037037037037, iteration : 26"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.608367673076, pas : 0.0357142857143, iteration : 27\n",
        "Norme du gradient : 0.616617064318, pas : 0.0344827586207, iteration : 28\n",
        "Norme du gradient : 0.613197756523, pas : 0.0333333333333, iteration : 29\n",
        "Norme du gradient : 0.609714070325, pas : 0.0322580645161, iteration : 30\n",
        "Norme du gradient : 0.603507283247, pas : 0.03125, iteration : 31"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.612113547028, pas : 0.030303030303, iteration : 32\n",
        "Norme du gradient : 0.624426529065, pas : 0.0294117647059, iteration : 33\n",
        "Norme du gradient : 0.588724109311, pas : 0.0285714285714, iteration : 34\n",
        "Norme du gradient : 0.627085462571, pas : 0.0277777777778, iteration : 35\n",
        "Norme du gradient : 0.605895129457, pas : 0.027027027027, iteration : 36"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.608965287287, pas : 0.0263157894737, iteration : 37\n",
        "Norme du gradient : 0.600942447526, pas : 0.025641025641, iteration : 38\n",
        "Norme du gradient : 0.618140920467, pas : 0.025, iteration : 39\n",
        "Norme du gradient : 0.610254602821, pas : 0.0243902439024, iteration : 40\n",
        "Norme du gradient : 0.593505676072, pas : 0.0238095238095, iteration : 41"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.612266748135, pas : 0.0232558139535, iteration : 42\n",
        "Norme du gradient : 0.609754434737, pas : 0.0227272727273, iteration : 43\n",
        "Norme du gradient : 0.612986618314, pas : 0.0222222222222, iteration : 44\n",
        "Norme du gradient : 0.596161164763, pas : 0.0217391304348, iteration : 45\n",
        "Norme du gradient : 0.624879727889, pas : 0.0212765957447, iteration : 46"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.580369483956, pas : 0.0208333333333, iteration : 47\n",
        "Norme du gradient : 0.629183321189, pas : 0.0204081632653, iteration : 48\n",
        "Norme du gradient : 0.601147781517, pas : 0.02, iteration : 49\n",
        "Norme du gradient : 0.597981036885, pas : 0.0196078431373, iteration : 50\n",
        "Gradient de norme : 0.597981036885, a l'iteration : 50\n",
        "LSPI, iter :1, diff : 9.64995948862"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :2, diff : 27.9148101058"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :3, diff : 0.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "RE: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "128.8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    }
   ],
   "metadata": {}
  }
 ]
}