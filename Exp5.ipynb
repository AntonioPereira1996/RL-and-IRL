{
 "metadata": {
  "name": "Exp5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Mountain Car\n",
      "from stuff import *\n",
      "from pylab import *\n",
      "from random import *\n",
      "import pickle\n",
      "import numpy\n",
      "from rl import *\n",
      "import sys\n",
      "\n",
      "NB_SAMPLES=100\n",
      "#NB_SAMPLES=int(sys.argv[1])\n",
      "RAND_STRING=str(int(rand()*10000000000))\n",
      "\n",
      "\n",
      "ACTION_SPACE=[-1,0,1]\n",
      "\n",
      "\n",
      "\n",
      "def mountain_car_next_state(state,action):\n",
      "    position,speed=state\n",
      "    next_speed = squeeze(speed+action*0.001+cos(3*position)*(-0.0025))\n",
      "    next_position = squeeze(position+next_speed)\n",
      "    if not -0.07 <= next_speed <= 0.07:\n",
      "        next_speed = sign(next_speed)*0.07\n",
      "    if not -1.2 <= next_position <= 0.6:\n",
      "        next_speed=0.\n",
      "        next_position = -1.2 if next_position < -1.2 else 0.6\n",
      "    return array([next_position,next_speed])\n",
      "\n",
      "def mountain_car_uniform_state():\n",
      "    return array([numpy.random.uniform(low=-1.2,high=0.6),numpy.random.uniform(low=-0.07,high=0.07)])\n",
      "\n",
      "mountain_car_mu_position, mountain_car_mu_speed = meshgrid(linspace(-1.2,0.6,7),linspace(-0.07,0.07,7))\n",
      "\n",
      "mountain_car_sigma_position = 2*pow((0.6+1.2)/10.,2)\n",
      "mountain_car_sigma_speed = 2*pow((0.07+0.07)/10.,2)\n",
      "\n",
      "def mountain_car_single_psi(state):\n",
      "    position,speed=state\n",
      "    psi=[]\n",
      "    for mu in zip_stack(mountain_car_mu_position, mountain_car_mu_speed).reshape(7*7,2):\n",
      "        psi.append(exp( -pow(position-mu[0],2)/mountain_car_sigma_position \n",
      "                        -pow(speed-mu[1],2)/mountain_car_sigma_speed))\n",
      "    psi.append(1.)\n",
      "    return array(psi).reshape((7*7+1,1))\n",
      "\n",
      "mountain_car_psi= non_scalar_vectorize(mountain_car_single_psi,(2,),(50,1))\n",
      "\n",
      "def mountain_car_single_phi(sa):\n",
      "    state=sa[:2]\n",
      "    index_action = int(sa[-1])+1\n",
      "    answer=zeros(((7*7+1)*3,1))\n",
      "    answer[index_action*(7*7+1):index_action*(7*7+1)+7*7+1] = mountain_car_psi(state)\n",
      "    return answer\n",
      "\n",
      "mountain_car_phi= non_scalar_vectorize(mountain_car_single_phi,(3,),(150,1))\n",
      "\n",
      "def mountain_car_reward(sas):\n",
      "    position=sas[0]\n",
      "    return 1 if position > 0.5 else 0\n",
      "\n",
      "def mountain_car_episode_length(initial_position,initial_speed,policy):\n",
      "    answer = 0\n",
      "    reward = 0.\n",
      "    state = array([initial_position,initial_speed])\n",
      "    while answer < 300 and reward == 0. :\n",
      "        action = policy(state)\n",
      "        next_state = mountain_car_next_state(state,action)\n",
      "        reward = mountain_car_reward(hstack([state, action, next_state]))\n",
      "        state=next_state\n",
      "        answer+=1\n",
      "    return answer\n",
      "\n",
      "def mountain_car_episode_vlength(policy):\n",
      "    return vectorize(lambda p,s:mountain_car_episode_length(p,s,policy))\n",
      "\n",
      "\n",
      "def mountain_car_training_data(freward=mountain_car_reward,traj_length=5,nb_traj=1000):\n",
      "    traj = []\n",
      "    random_policy = lambda s:choice(ACTION_SPACE)\n",
      "    for i in range(0,nb_traj):\n",
      "        state = mountain_car_uniform_state()\n",
      "        reward=0\n",
      "        t=0\n",
      "        while t < traj_length and reward == 0:\n",
      "            t+=1\n",
      "            action = random_policy(state)\n",
      "            next_state = mountain_car_next_state(state, action)\n",
      "            reward = freward(hstack([state, action, next_state]))\n",
      "            traj.append(hstack([state, action, next_state, reward]))\n",
      "            state=next_state\n",
      "    return array(traj)\n",
      "\n",
      "def mountain_car_manual_policy(state):\n",
      "    position,speed = state\n",
      "    return -1. if speed <=0 else 1.\n",
      "\n",
      "def mountain_car_interesting_state():\n",
      "    position = numpy.random.uniform(low=-1.2,high=-0.9)\n",
      "    speed = numpy.random.uniform(low=-0.07,high=0)\n",
      "    return array([position,speed])\n",
      "\n",
      "def mountain_car_IRL_traj():\n",
      "    traj = []\n",
      "    state = mountain_car_interesting_state()\n",
      "    reward = 0\n",
      "    while reward == 0:\n",
      "        action = mountain_car_manual_policy(state)\n",
      "        next_state = mountain_car_next_state(state, action)\n",
      "        next_action = mountain_car_manual_policy(next_state)\n",
      "        reward = mountain_car_reward(hstack([state, action, next_state]))\n",
      "        traj.append(hstack([state, action, next_state, next_action, reward]))\n",
      "        state=next_state\n",
      "    return array(traj)\n",
      "\n",
      "def mountain_car_IRL_data(nbsamples):\n",
      "    data = mountain_car_IRL_traj()\n",
      "    while len(data) < nbsamples:\n",
      "        data = vstack([data,mountain_car_IRL_traj()])\n",
      "    return data[:nbsamples]\n",
      "\n",
      "TRAJS = mountain_car_IRL_data(NB_SAMPLES)\n",
      "\n",
      "psi=mountain_car_psi\n",
      "phi=mountain_car_phi\n",
      "s=TRAJS[:,:2]\n",
      "a=TRAJS[:,2]\n",
      "#Classification\n",
      "from sklearn import svm\n",
      "clf = svm.SVC(C=1, probability=True, gamma=1/(2*pow(0.03,2)))\n",
      "clf.fit(s, a)\n",
      "def clf_predict(state):\n",
      "    try:\n",
      "        return clf.predict(squeeze(state))\n",
      "    except ValueError:\n",
      "        return 1.\n",
      "vpredict = non_scalar_vectorize( clf_predict, (2,), (1,1) )\n",
      "pi_c = lambda state: vpredict(state).reshape(state.shape[:-1]+(1,))\n",
      "def clf_score(sa):\n",
      "    #try:\n",
      "    action = sa[-1]\n",
      "    index=0\n",
      "    if action == -1.:\n",
      "        index = 0\n",
      "    elif action == 1.:\n",
      "        index = 1\n",
      "    else:\n",
      "        return 0\n",
      "    return squeeze(clf.predict_proba(squeeze(sa[:2])))[sa[index]]\n",
      "vscore = non_scalar_vectorize( clf_score,(3,),(1,1) )\n",
      "q = lambda sa: vscore(sa).reshape(sa.shape[:-1])\n",
      "#Donn\u00e9es pour la regression\n",
      "column_shape = (len(TRAJS),1)\n",
      "s = TRAJS[:,0:2]\n",
      "a = TRAJS[:,2].reshape(column_shape)\n",
      "sa = TRAJS[:,0:3]\n",
      "s_dash = TRAJS[:,3:5]\n",
      "a_dash = pi_c(s_dash).reshape(column_shape)\n",
      "sa_dash = hstack([s_dash,a_dash])\n",
      "hat_r = (q(sa)-GAMMA*q(sa_dash)).reshape(column_shape)\n",
      "r_min = min(hat_r)-1.*ones(column_shape)\n",
      "\n",
      "##Avec l'heuristique : \n",
      "regression_input_matrices = [hstack([s,action*ones(column_shape)]) for action in ACTION_SPACE] \n",
      "def add_output_column( reg_mat ):\n",
      "    actions = reg_mat[:,-1].reshape(column_shape)\n",
      "    hat_r_bool_table = array(actions==a)\n",
      "    r_min_bool_table = array(hat_r_bool_table==False) #\"not hat_r_bool_table\" does not work as I expected\n",
      "    output_column = hat_r_bool_table*hat_r+r_min_bool_table*r_min\n",
      "    return hstack([reg_mat,output_column])\n",
      "regression_matrix = vstack(map(add_output_column,regression_input_matrices))\n",
      "#R\u00e9gression\n",
      "from sklearn.svm import SVR\n",
      "y = regression_matrix[:,-1]\n",
      "X = regression_matrix[:,:-1]\n",
      "reg = SVR(C=1.0, epsilon=0.2, gamma=1/(2*pow(0.03,2)))\n",
      "reg.fit(X, y)\n",
      "CSI_reward = lambda sas:reg.predict(sas[:3])[0]\n",
      "vCSI_reward = non_scalar_vectorize( CSI_reward, (5,),(1,1) )\n",
      "data = genfromtxt(\"mountain_car_batch_data.mat\")\n",
      "data[:,5] = squeeze(vCSI_reward(data[:,:5]))\n",
      "policy_CSI,omega_CSI = lspi( data, s_dim=2,a_dim=1, A=ACTION_SPACE, phi=mountain_car_phi, phi_dim=150, iterations_max=20 )\n",
      "def mountain_car_testing_state():\n",
      "    position = numpy.random.uniform(low=-1.2,high=0.5)\n",
      "    speed = numpy.random.uniform(low=-0.07,high=0.07)\n",
      "    return array([position,speed])\n",
      "\n",
      "def mountain_car_mean_performance(policy):\n",
      "    return mean([mountain_car_episode_length(state[0],state[1],policy) for state in [mountain_car_testing_state() for i in range(0,100)]])\n",
      "print \"Samples : \"+str(NB_SAMPLES)\n",
      "print \"CSI, classif : \"\n",
      "print mountain_car_mean_performance(policy_CSI),mountain_car_mean_performance(pi_c)\n",
      "savetxt(\"data/CSI_omega_\"+str(NB_SAMPLES)+\"_\"+RAND_STRING+\".mat\",omega_CSI)\n",
      "with open('data/Classif_'+str(NB_SAMPLES)+\"_\"+RAND_STRING+\".obj\", 'wb') as output:\n",
      "    pickle.dump(clf, output, pickle.HIGHEST_PROTOCOL)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LSPI, iter :1, diff : 52.6591224505\n",
        "LSPI, iter :2, diff : 45.6358705211"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :3, diff : 3.319005575"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :4, diff : 0.202402865665"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :5, diff : 0.000589097330516"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Samples : 100"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "CSI, classif : \n",
        "59.34"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 96.27\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "psi=mountain_car_psi\n",
      "phi=mountain_car_phi\n",
      "s=TRAJS[:,:2]\n",
      "a=TRAJS[:,2]\n",
      "\n",
      "s_dash=TRAJS[:,3:5]\n",
      "a_dash=TRAJS[:,5]\n",
      "sa=TRAJS[:,:3]\n",
      "sa_dash=TRAJS[:,3:6]\n",
      "\n",
      "##SCIRL\n",
      "#Precomputing mu with LSTDmu and heuristics\n",
      "A = zeros((150,150))\n",
      "b = zeros((150,50))\n",
      "phi_t = phi(sa)\n",
      "phi_t_dash = phi(sa_dash)\n",
      "psi_t = psi(s)\n",
      "for phi_t,phi_t_dash,psi_t in zip(phi_t,phi_t_dash,psi_t):\n",
      "    A = A + dot(phi_t,\n",
      "            (phi_t - GAMMA*phi_t_dash).transpose())\n",
      "    b = b + dot(phi_t,psi_t.transpose())\n",
      "omega_lstd_mu = dot(inv(A+0.1*identity(150)),b)\n",
      "phi_t.shape, phi_t_dash.shape, psi_t.shape\n",
      "feature_expectations = {}\n",
      "for state,action in zip(s,a):\n",
      "    state_action = hstack([state,action])\n",
      "    mu = dot(omega_lstd_mu.transpose(),phi(state_action))\n",
      "    feature_expectations[str(state_action)] = mu\n",
      "    for other_action in [a for a in ACTION_SPACE if a != action]:\n",
      "        state_action=hstack([state,other_action])\n",
      "        feature_expectations[str(state_action)]=GAMMA*mu\n",
      "        \n",
      "        \n",
      "#Precomputing mu with MC and heuristics\n",
      "feature_expectations_MC = {}\n",
      "for start_index in range(0,len(TRAJS)):\n",
      "    end_index = (i for i in range(start_index,len(TRAJS)) if TRAJS[i,6] == 1 or i==len(TRAJS)-1).next()\n",
      "    #print \"start_index : \"+str(start_index)+\" end_index : \"+str(end_index)\n",
      "    data_MC=TRAJS[start_index:end_index+1,:3]\n",
      "    GAMMAS = range(0,len(data_MC))\n",
      "    GAMMAS = array(map( lambda x: pow(GAMMA,x), GAMMAS))\n",
      "    state_action = data_MC[0,:3]\n",
      "    state = data_MC[0,:2]\n",
      "    action = data_MC[0,2]\n",
      "    mu = None\n",
      "    if len(data_MC) > 1:\n",
      "        mu = dot( GAMMAS,squeeze(psi(data_MC[:,:2])))\n",
      "    else:\n",
      "        mu = squeeze(psi(squeeze(data_MC[:,:2])))\n",
      "    feature_expectations_MC[str(state_action)] = mu\n",
      "    for other_action in [a for a in ACTION_SPACE if a != action]:\n",
      "        state_action=hstack([state,other_action])\n",
      "        feature_expectations_MC[str(state_action)]=GAMMA*mu\n",
      "        \n",
      "\n",
      "#Structured Classifier\n",
      "class GradientDescent(object):\n",
      "    \n",
      "   def alpha( self, t ):\n",
      "      raise NotImplementedError, \"Cannot call abstract method\"\n",
      "\n",
      "   theta_0=None\n",
      "   Threshold=None\n",
      "   T = -1\n",
      "   sign = None\n",
      "        \n",
      "   def run( self, f_grad, f_proj=None, b_norm=False ): #grad is a function of theta\n",
      "      theta = self.theta_0.copy()\n",
      "      best_theta = theta.copy()\n",
      "      best_norm = float(\"inf\")\n",
      "      best_iter = 0\n",
      "      t=0\n",
      "      while True:#Do...while loop\n",
      "         t+=1\n",
      "         DeltaTheta = f_grad( theta )\n",
      "         current_norm = norm( DeltaTheta )\n",
      "         if b_norm and  current_norm > 0.:\n",
      "             DeltaTheta /= norm( DeltaTheta )\n",
      "         theta = theta + self.sign * self.alpha( t )*DeltaTheta\n",
      "         if f_proj:\n",
      "             theta = f_proj( theta )\n",
      "         print \"Norme du gradient : \"+str(current_norm)+\", pas : \"+str(self.alpha(t))+\", iteration : \"+str(t)\n",
      "\n",
      "         if current_norm < best_norm:\n",
      "             best_norm = current_norm\n",
      "             best_theta = theta.copy()\n",
      "             best_iter = t\n",
      "         if current_norm < self.Threshold or (self.T != -1 and t >= self.T):\n",
      "             break\n",
      "\n",
      "      print \"Gradient de norme : \"+str(best_norm)+\", a l'iteration : \"+str(best_iter)\n",
      "      return best_theta\n",
      "\n",
      "\n",
      "class StructuredClassifier(GradientDescent):\n",
      "    sign=-1.\n",
      "    Threshold=0.1 #Sensible default\n",
      "    T=40 #Sensible default\n",
      "    phi=None\n",
      "    phi_xy=None\n",
      "    inputs=None\n",
      "    labels=None\n",
      "    label_set=None\n",
      "    dic_data={}\n",
      "    x_dim=None\n",
      "    \n",
      "    def alpha(self, t):\n",
      "        return 3./(t+1)#Sensible default\n",
      "    \n",
      "    def __init__(self, data, x_dim, phi, phi_dim, Y):\n",
      "        self.x_dim=x_dim\n",
      "        self.inputs = data[:,:-1]\n",
      "        shape = list(data.shape)\n",
      "        shape[-1] = 1\n",
      "        self.labels = data[:,-1].reshape(shape)\n",
      "        self.phi=phi\n",
      "        self.label_set = Y\n",
      "        self.theta_0 = zeros((phi_dim,1))\n",
      "        self.phi_xy = self.phi(data)\n",
      "        for x,y in zip(self.inputs,self.labels):\n",
      "            self.dic_data[str(x)] = y\n",
      "        print self.inputs.shape\n",
      "    \n",
      "    def structure(self, xy):\n",
      "        return 0. if xy[-1] == self.dic_data[str(xy[:-1])] else 1.\n",
      "        \n",
      "    def structured_decision(self, theta):\n",
      "        def decision( x ):\n",
      "            score = lambda xy: dot(theta.transpose(),self.phi(xy)) + self.structure(xy)\n",
      "            input_label_couples = [hstack([x,y]) for y in self.label_set]\n",
      "            best_label = argmax(input_label_couples, score)[-1]\n",
      "            return best_label\n",
      "        vdecision = non_scalar_vectorize(decision, (self.x_dim,), (1,1))\n",
      "        return lambda x: vdecision(x).reshape(x.shape[:-1]+(1,))\n",
      "    \n",
      "    def gradient(self, theta):\n",
      "        classif_rule = self.structured_decision(theta)\n",
      "        y_star = classif_rule(self.inputs)\n",
      "        #print \"Gradient : \"+str(y_star)\n",
      "        #print str(self.labels)\n",
      "        phi_star = self.phi(hstack([self.inputs,y_star]))\n",
      "        return mean(phi_star-self.phi_xy,axis=0)\n",
      "    \n",
      "    def run(self):\n",
      "        f_grad = lambda theta: self.gradient(theta)\n",
      "        theta = super(StructuredClassifier,self).run( f_grad, b_norm=True)\n",
      "        classif_rule = greedy_policy(theta,self.phi,self.label_set)\n",
      "        return classif_rule,theta\n",
      "\n",
      "#Version LSTDmu    \n",
      "single_mu = lambda sa:feature_expectations[str(sa)]\n",
      "mu_E = non_scalar_vectorize(single_mu, (3,), (50,1))\n",
      "SCIRL = StructuredClassifier(sa, 2, mu_E, 50, ACTION_SPACE)\n",
      "void,theta_SCIRL = SCIRL.run()\n",
      "#Evaluation de SCIRL\n",
      "SCIRL_reward = lambda sas:dot(theta_SCIRL.transpose(),psi(sas[:2]))[0]\n",
      "vSCIRL_reward = non_scalar_vectorize( SCIRL_reward, (5,),(1,1) )\n",
      "data = genfromtxt(\"mountain_car_batch_data.mat\")\n",
      "data[:,5] = squeeze(vSCIRL_reward(data[:,:5]))\n",
      "policy_SCIRL,omega_SCIRL = lspi( data, s_dim=2,a_dim=1, A=ACTION_SPACE, phi=mountain_car_phi, phi_dim=150, iterations_max=20 )#None,zeros((75,1))#\n",
      "savetxt(\"data/SCIRL_omega_\"+str(NB_SAMPLES)+\"_\"+RAND_STRING+\".mat\",omega_SCIRL)\n",
      "#Version MC_mu\n",
      "single_mu = lambda sa:feature_expectations_MC[str(sa)]\n",
      "mu_E = non_scalar_vectorize(single_mu, (3,), (50,1))\n",
      "SCIRL_MC = StructuredClassifier(sa, 2, mu_E, 50, ACTION_SPACE)\n",
      "void,theta_SCIRL_MC = SCIRL_MC.run()\n",
      "#Evaluation de SCIRL\n",
      "SCIRL_reward = lambda sas:dot(theta_SCIRL_MC.transpose(),psi(sas[:2]))[0]\n",
      "vSCIRL_reward = non_scalar_vectorize( SCIRL_reward, (5,),(1,1) )\n",
      "data = genfromtxt(\"mountain_car_batch_data.mat\")\n",
      "data[:,5] = squeeze(vSCIRL_reward(data[:,:5]))\n",
      "policy_SCIRL_MC,omega_SCIRL_MC = lspi( data, s_dim=2,a_dim=1, A=ACTION_SPACE, phi=mountain_car_phi, phi_dim=150, iterations_max=20 )#None,zeros((75,1))#\n",
      "savetxt(\"data/SCIRLMC_omega_\"+str(NB_SAMPLES)+\"_\"+RAND_STRING+\".mat\",omega_SCIRL_MC)\n",
      "print \"SCIRL, SCIRL MC : \"\n",
      "print mountain_car_mean_performance(policy_SCIRL),mountain_car_mean_performance(policy_SCIRL_MC)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 2)\n",
        "Norme du gradient : 1.09003001714, pas : 1.5, iteration : 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.0, pas : 1.0, iteration : 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Gradient de norme : 0.0, a l'iteration : 2\n",
        "LSPI, iter :1, diff : 26.5752239276"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :2, diff : 5.51043352901"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :3, diff : 0.734627004251"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :4, diff : 0.103770770992"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :5, diff : 0.000738663121851"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(1000, 2)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.784504467549, pas : 1.5, iteration : 1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.133668617058, pas : 1.0, iteration : 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.0346824058219, pas : 0.75, iteration : 3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Gradient de norme : 0.0346824058219, a l'iteration : 3\n",
        "LSPI, iter :1, diff : 60.2128697964"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :2, diff : 17.7516913011"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :3, diff : 1.3663127218"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :4, diff : 0.0917670896581"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :5, diff : 0.00250334947525"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "SCIRL, SCIRL MC : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "58.76"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 56.68\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "GAMMA = 0.99\n",
      "\n",
      "def end_of_episode(data,i):\n",
      "    try:\n",
      "        if all(data[i,3:5] == data[i+1,:2]):\n",
      "            return False\n",
      "        else:\n",
      "            return True\n",
      "    except:\n",
      "        return True\n",
      "\n",
      "#function reward=relative_entropy_boularias(phi,n_s,gamma,data_c,data_r,L_c,H_c,L_r,H_r,delta,epsilon_re,N_final)\n",
      "def relative_entropy(data_c,data_r,delta):\n",
      "    #size_phi=size(phi);\n",
      "    \n",
      "    #feature_c=zeros(L_c,size_phi(2));\n",
      "    #feature_r=zeros(L_r,size_phi(2));\n",
      "    feature_c=[]\n",
      "    feature_r=[]\n",
      "    \n",
      "    #theta=zeros(1,size_phi(2));\n",
      "    theta=zeros((1,150))\n",
      "    #for i=1:L_c\n",
      "        #for j=1:H_c\n",
      "    eoe_indices = [i for i in range(0,len(data_c)) if end_of_episode(data_c,i)]\n",
      "    for start_index,end_index in zip( [0] + map(lambda x:x+1,eoe_indices[:-1]),eoe_indices):\n",
      "        #feature_c(i,:)=feature_c(i,:)+gamma^j*phi(data_c(j+H_c*(i-1),1)+n_s*(data_c(j+H_c*(i-1),2)-1),:);\n",
      "        data_MC=data_c[start_index:end_index+1,:3]\n",
      "        GAMMAS = range(0,len(data_MC))\n",
      "        GAMMAS = array(map( lambda x: pow(GAMMA,x), GAMMAS))\n",
      "        state_action = data_MC[0,:3]\n",
      "        mu = None\n",
      "        if len(data_MC) > 1:\n",
      "            mu = dot( GAMMAS,squeeze(phi(data_MC[:,:3])))\n",
      "        else:\n",
      "            mu = squeeze(phi(squeeze(data_MC[:,:3])))\n",
      "        feature_c.append(mu)   \n",
      "    feature_c=array(feature_c)\n",
      "\n",
      "    #feature_c_mean=mean(feature_c,1);\n",
      "    feature_c_mean=mean(feature_c,0);\n",
      "    \n",
      "    #epsilon=sqrt(-log2(1-delta)/(2*H_c))*(gamma^(H_c+1)-1)/(gamma-1);\n",
      "    #epsilon=sqrt(-log2(1-delta)/(2*300))*(pow(GAMMA,(300+1))-1)/(GAMMA-1);\n",
      "    epsilon = 0.01\n",
      "    print \"epsilon \"+str(epsilon)\n",
      "    \n",
      "    #for i=1:L_r\n",
      "    #    for j=1:H_r\n",
      "    eoe_indices = [i for i in range(0,len(data_r)) if end_of_episode(data_r,i)]\n",
      "    for start_index,end_index in zip( [0] + map(lambda x:x+1,eoe_indices[:-1]),eoe_indices):\n",
      "        #feature_r(i,:)=feature_r(i,:)+gamma^j*phi(data_r(j+H_r*(i-1),1)+n_s*(data_r(j+H_r*(i-1),2)-1),:)\n",
      "        data_MC=data_r[start_index:end_index+1,:3]\n",
      "        GAMMAS = range(0,len(data_MC))\n",
      "        GAMMAS = array(map( lambda x: pow(GAMMA,x), GAMMAS))\n",
      "        state_action = data_MC[0,:3]\n",
      "        mu = None\n",
      "        if len(data_MC) > 1:\n",
      "            mu = dot( GAMMAS,squeeze(phi(data_MC[:,:3])))\n",
      "        else:\n",
      "            mu = squeeze(phi(squeeze(data_MC[:,:3])))\n",
      "        feature_r.append(mu)\n",
      "        #    end   \n",
      "        #end\n",
      "    feature_r=array(feature_r)\n",
      "\n",
      "    #Criterion=epsilon_re+1;\n",
      "    criterion=numpy.inf\n",
      "    #counter=1;\n",
      "    counter=1\n",
      "\n",
      "    #while Criterion>epsilon_re&&counter<N_final\n",
      "    while criterion > 0.01 and counter < 100:\n",
      "        #buffer_derivative_t=zeros(1,size_phi(2));\n",
      "        derivative = zeros((1,150))\n",
      "        #buffer_t=0;\n",
      "        t = 0\n",
      "        #buffer_theta=theta;\n",
      "        #for i=1:L_r\n",
      "        for i in range(0,len(feature_r)):\n",
      "            #buffer_derivative_t=buffer_derivative_t+exp(theta*feature_r(i,:)')*feature_r(i,:);\n",
      "            derivative += exp(dot(theta,feature_r[i,:].transpose()))*feature_r[i,:]\n",
      "            #buffer_t=buffer_t+exp(theta*feature_r(i,:)');\n",
      "            t +=  exp(dot(theta,feature_r[i,:].transpose()))\n",
      "            #end    \n",
      "\n",
      "        #buffer_derivative=feature_c_mean-buffer_derivative_t/(buffer_t)-sign(theta)*epsilon;\n",
      "        derivative=feature_c_mean-derivative/(t)-sign(theta)*epsilon\n",
      "\n",
      "        print \"Boubou run \\t\"+str(counter)+\" criterion is \\t\"+str(criterion)+\" ||derivative|| is \\t\"+str(norm(derivative))\n",
      "        if isnan(derivative):\n",
      "            raise Exception\n",
      "        \n",
      "        #if norm(buffer_derivative)==0\n",
      "        if norm(derivative)==0:\n",
      "            #theta=buffer_theta;\n",
      "            break\n",
      "        else:\n",
      "            #theta=buffer_theta+(1/counter)*buffer_derivative/norm(buffer_derivative,2);\n",
      "            delta_theta = (100./float(counter))*derivative/norm(derivative,2)\n",
      "            #end\n",
      "        #Criterion=norm(buffer_theta-theta,2);\n",
      "        criterion=norm(delta_theta,2)\n",
      "        theta+=delta_theta\n",
      "        #counter=counter+1;    \n",
      "        counter += 1\n",
      "        #end    \n",
      "    print \"Stop boubou @ run \"+str(counter-1)+\" criterion is \"+str(criterion)\n",
      "    #reward=phi*theta';\n",
      "    return lambda sas: dot(theta,phi(sas[:3]))[0]\n",
      "    \n",
      "\n",
      "#data_r = genfromtxt(\"mountain_car_batch_data.mat\")\n",
      "data_r = genfromtxt(\"mountain_car_boubou_trajs.mat\")\n",
      "\n",
      "toto = True\n",
      "while toto:\n",
      "    try:\n",
      "        RE_reward = relative_entropy(TRAJS, data_r, 0.99)\n",
      "        toto = False\n",
      "    except Exception:\n",
      "        pass\n",
      "vRE_reward = non_scalar_vectorize( RE_reward, (5,),(1,1) )\n",
      "data = genfromtxt(\"mountain_car_batch_data.mat\")\n",
      "data[:,5] = squeeze(vRE_reward(data[:,:5]))\n",
      "policy_RE,omega_RE = lspi( data, s_dim=2,a_dim=1, A=ACTION_SPACE, phi=mountain_car_phi, phi_dim=150, iterations_max=20 )#None,zeros((75,1))#\n",
      "savetxt(\"data/Boubou_omega_\"+str(NB_SAMPLES)+\"_\"+RAND_STRING+\".mat\",omega_RE)\n",
      "print \"Relative entropy : \"\n",
      "print mountain_car_mean_performance(policy_RE)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epsilon 0.01\n",
        "Boubou run \t1 criterion is \tinf ||derivative|| is \t27.4468580146"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Boubou run \t2 criterion is \t100.0 ||derivative|| is \t17.3579679273\n",
        "Boubou run \t3 criterion is \t50.0 ||derivative|| is \t17.3537514755\n",
        "Boubou run \t4 criterion is \t33.3333333333 ||derivative|| is \t17.3537110482\n",
        "Boubou run \t5 criterion is \t25.0 ||derivative|| is \t17.3537138951\n",
        "Boubou run \t6 criterion is \t20.0 ||derivative|| is \t17.3537142918\n",
        "Boubou run \t7 criterion is \t16.6666666667 ||derivative|| is \t17.3537110381\n",
        "Boubou run \t8 criterion is \t14.2857142857 ||derivative|| is \t21.0762788789"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Boubou run \t9 criterion is \t12.5 ||derivative|| is \t17.3537139328\n",
        "Boubou run \t10 criterion is \t11.1111111111 ||derivative|| is \t17.3537154468\n",
        "Boubou run \t11 criterion is \t10.0 ||derivative|| is \t17.3537099301\n",
        "Boubou run \t12 criterion is \t9.09090909091 ||derivative|| is \t17.3537150766\n",
        "Boubou run \t13 criterion is \t8.33333333333 ||derivative|| is \t17.3534415667\n",
        "Boubou run \t14 criterion is \t7.69230769231 ||derivative|| is \t21.0732177734\n",
        "Boubou run \t15 criterion is \t7.14285714286 ||derivative|| is \t17.3537116223"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Boubou run \t16 criterion is \t6.66666666667 ||derivative|| is \t17.353713384\n",
        "Boubou run \t17 criterion is \t6.25 ||derivative|| is \t17.3537120175\n",
        "Boubou run \t18 criterion is \t5.88235294118 ||derivative|| is \t17.3537052344\n",
        "Boubou run \t19 criterion is \t5.55555555556 ||derivative|| is \t18.0308737464\n",
        "Boubou run \t20 criterion is \t5.26315789474 ||derivative|| is \t17.3536945531\n",
        "Boubou run \t21 criterion is \t5.0 ||derivative|| is \t17.3536889018\n",
        "Boubou run \t22 criterion is \t4.7619047619 ||derivative|| is \t17.1981925804"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Boubou run \t23 criterion is \t4.54545454545 ||derivative|| is \t20.2731993513\n",
        "Boubou run \t24 criterion is \t4.34782608696 ||derivative|| is \t17.353692867\n",
        "Boubou run \t25 criterion is \t4.16666666667 ||derivative|| is \t17.3537016801\n",
        "Boubou run \t26 criterion is \t4.0 ||derivative|| is \t17.3536932315\n",
        "Boubou run \t27 criterion is \t3.84615384615 ||derivative|| is \t17.3456028526\n",
        "Boubou run \t28 criterion is \t3.7037037037 ||derivative|| is \t20.3867800196\n",
        "Boubou run \t29 criterion is \t3.57142857143 ||derivative|| is \t17.3536933823"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Boubou run \t30 criterion is \t3.44827586207 ||derivative|| is \t17.3536945401\n",
        "Boubou run \t31 criterion is \t3.33333333333 ||derivative|| is \t17.3536698493\n",
        "Boubou run \t32 criterion is \t3.22580645161 ||derivative|| is \t17.3196276523\n",
        "Boubou run \t33 criterion is \t3.125 ||derivative|| is \t20.2211421774\n",
        "Boubou run \t34 criterion is \t3.0303030303 ||derivative|| is \t17.3536968417\n",
        "Boubou run \t35 criterion is \t2.94117647059 ||derivative|| is \t17.3536971027\n",
        "Boubou run \t36 criterion is \t2.85714285714 ||derivative|| is \t17.3533699944"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Boubou run \t37 criterion is \t2.77777777778 ||derivative|| is \t17.2392626564\n",
        "Boubou run \t38 criterion is \t2.7027027027 ||derivative|| is \t19.1983143072\n",
        "Boubou run \t39 criterion is \t2.63157894737 ||derivative|| is \t17.3536927909\n",
        "Boubou run \t40 criterion is \t2.5641025641 ||derivative|| is \t17.3536454965\n",
        "Boubou run \t41 criterion is \t2.5 ||derivative|| is \t17.3417185809\n",
        "Boubou run \t42 criterion is \t2.43902439024 ||derivative|| is \t17.8432719537\n",
        "Boubou run \t43 criterion is \t2.38095238095 ||derivative|| is \t17.3535508716"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Boubou run \t44 criterion is \t2.32558139535 ||derivative|| is \t17.3307612414\n",
        "Boubou run \t45 criterion is \t2.27272727273 ||derivative|| is \t18.0224598131\n",
        "Boubou run \t46 criterion is \t2.22222222222 ||derivative|| is \t17.35357736\n",
        "Boubou run \t47 criterion is \t2.17391304348 ||derivative|| is \t17.3403789089\n",
        "Boubou run \t48 criterion is \t2.12765957447 ||derivative|| is \t17.3901666098\n",
        "Boubou run \t49 criterion is \t2.08333333333 ||derivative|| is \t17.3453018721\n",
        "Boubou run \t50 criterion is \t2.04081632653 ||derivative|| is \t17.1878934149"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Boubou run \t51 criterion is \t2.0 ||derivative|| is \t17.249864881\n",
        "Boubou run \t52 criterion is \t1.96078431373 ||derivative|| is \t17.9594828637\n",
        "Boubou run \t53 criterion is \t1.92307692308 ||derivative|| is \t17.3531344982\n",
        "Boubou run \t54 criterion is \t1.88679245283 ||derivative|| is \t17.320150717\n",
        "Boubou run \t55 criterion is \t1.85185185185 ||derivative|| is \t17.4826873309\n",
        "Boubou run \t56 criterion is \t1.81818181818 ||derivative|| is \t17.3452906772\n",
        "Boubou run \t57 criterion is \t1.78571428571 ||derivative|| is \t17.1631196875"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Boubou run \t58 criterion is \t1.75438596491 ||derivative|| is \t17.1755268867\n",
        "Boubou run \t59 criterion is \t1.72413793103 ||derivative|| is \t17.2062301238\n",
        "Boubou run \t60 criterion is \t1.69491525424 ||derivative|| is \t17.430123201\n",
        "Boubou run \t61 criterion is \t1.66666666667 ||derivative|| is \t17.3363587598\n",
        "Boubou run \t62 criterion is \t1.6393442623 ||derivative|| is \t17.1660364862\n",
        "Boubou run \t63 criterion is \t1.61290322581 ||derivative|| is \t17.1776878489\n",
        "Boubou run \t64 criterion is \t1.5873015873 ||derivative|| is \t17.2392667289"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Boubou run \t65 criterion is \t1.5625 ||derivative|| is \t17.2721649133\n",
        "Boubou run \t66 criterion is \t1.53846153846 ||derivative|| is \t17.3989511072\n",
        "Boubou run \t67 criterion is \t1.51515151515 ||derivative|| is \t17.3237760178\n",
        "Boubou run \t68 criterion is \t1.49253731343 ||derivative|| is \t17.1794361277\n",
        "Boubou run \t69 criterion is \t1.47058823529 ||derivative|| is \t17.1992874213\n",
        "Boubou run \t70 criterion is \t1.44927536232 ||derivative|| is \t17.2790863152\n",
        "Boubou run \t71 criterion is \t1.42857142857 ||derivative|| is \t17.281469897"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Boubou run \t72 criterion is \t1.40845070423 ||derivative|| is \t17.2751577958\n",
        "Boubou run \t73 criterion is \t1.38888888889 ||derivative|| is \t17.2752377458\n",
        "Boubou run \t74 criterion is \t1.3698630137 ||derivative|| is \t17.2640447508\n",
        "Boubou run \t75 criterion is \t1.35135135135 ||derivative|| is \t17.2652210734\n",
        "Boubou run \t76 criterion is \t1.33333333333 ||derivative|| is \t17.2583300261\n",
        "Boubou run \t77 criterion is \t1.31578947368 ||derivative|| is \t17.2578726612\n",
        "Boubou run \t78 criterion is \t1.2987012987 ||derivative|| is \t17.2482383266"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Boubou run \t79 criterion is \t1.28205128205 ||derivative|| is \t17.2478946686\n",
        "Boubou run \t80 criterion is \t1.26582278481 ||derivative|| is \t17.2399286394\n",
        "Boubou run \t81 criterion is \t1.25 ||derivative|| is \t17.2388542856\n",
        "Boubou run \t82 criterion is \t1.23456790123 ||derivative|| is \t17.230550311\n",
        "Boubou run \t83 criterion is \t1.21951219512 ||derivative|| is \t17.22907439\n",
        "Boubou run \t84 criterion is \t1.20481927711 ||derivative|| is \t17.2211877581"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Boubou run \t85 criterion is \t1.19047619048 ||derivative|| is \t17.2192908347\n",
        "Boubou run \t86 criterion is \t1.17647058824 ||derivative|| is \t17.2117786725\n",
        "Boubou run \t87 criterion is \t1.16279069767 ||derivative|| is \t17.2095167546\n",
        "Boubou run \t88 criterion is \t1.14942528736 ||derivative|| is \t17.2024822966\n",
        "Boubou run \t89 criterion is \t1.13636363636 ||derivative|| is \t17.1999663617\n",
        "Boubou run \t90 criterion is \t1.12359550562 ||derivative|| is \t17.1935785856\n",
        "Boubou run \t91 criterion is \t1.11111111111 ||derivative|| is \t17.1908980519"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Boubou run \t92 criterion is \t1.0989010989 ||derivative|| is \t17.1853051689\n",
        "Boubou run \t93 criterion is \t1.08695652174 ||derivative|| is \t17.1826581945\n",
        "Boubou run \t94 criterion is \t1.0752688172 ||derivative|| is \t17.1779763573\n",
        "Boubou run \t95 criterion is \t1.06382978723 ||derivative|| is \t17.1755425861\n",
        "Boubou run \t96 criterion is \t1.05263157895 ||derivative|| is \t17.1719031244\n",
        "Boubou run \t97 criterion is \t1.04166666667 ||derivative|| is \t17.1698471592\n",
        "Boubou run \t98 criterion is \t1.03092783505 ||derivative|| is \t17.167258713"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Boubou run \t99 criterion is \t1.02040816327 ||derivative|| is \t17.1657313166\n",
        "Stop boubou @ run 99 criterion is 1.0101010101\n",
        "LSPI, iter :1, diff : 5144.57535019"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :2, diff : 11147.947019"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "LSPI, iter :3, diff : 0.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Relative entropy : "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "119.03"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 10
    }
   ],
   "metadata": {}
  }
 ]
}