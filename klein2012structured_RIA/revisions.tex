\documentclass[11pt, a4paper]{letter}
\usepackage[plain,cm]{fullpage}
\usepackage[utf8] {inputenc}
\usepackage[frenchb]  {babel}
\usepackage  {color}


% \usepackage{lmodern}
% \renewcommand*\familydefault{\ttdefault} %% Only if the base font of the document is to be typewriter style
\usepackage[T1]{fontenc}

% \usepackage[default]{frcursive}

% \usepackage{inconsolata}
% % \renewcommand{\familydefault}{\ttdefault}
% % \renewcommand{\ttdefault}{pcr}
% \usepackage[T1]{fontenc}


\usepackage{anysize}
\marginsize{2.5cm}{2.5cm}{2cm}{2cm}

\definecolor{blue}{rgb}{0.2,0.3,1}

\newcommand{\R}{\mathcal{R}}

\begin{document}


% \pagestyle{plain}

%\tt
\color{blue}

\address{Edouard Klein,  Matthieu Geist, \\Bilal Piot, Olivier Pietquin \\ IMS – MaLIS Research Group, Sup\'elec \\ 2 rue Edouard Belin, 57070 Metz (France)}
%\signature{Lucie Daubigney, \\ Matthieu Geist, \\ Senthilkumar Chandramohan, \\ Olivier Pietquin.}
\date{Metz, \today. \vspace{1.5cm}}



\begin{letter}{\large \textbf{Révisions sur le manuscrit ``Classification structurée pour l'apprentissage par renforcement inverse''}}
\bigskip
\opening{Chers éditeurs, Chers reviewers}

\bigskip

Nous vous remercions pour le temps passé à relire notre manuscrit. Les remarques des reviewers étant largement orthogonales, nous les prenons en compte une par une. Les changements apportés au manuscrit sont reportés ici en bleu.

\newpage
\color{black}
\begin{large} \textbf{Reviewer 1:} \\ \end{large}
\textcolor{blue}{
Toutes les corrections suggérées ont été appliquées.
}

\newpage
\begin{large} \textbf{Reviewer 2:} \\ \end{large}
\begin{itemize}
\item  On sent bien qu'il faudrait une normalisation (c'est plus ou moins esquissée par les auteurs). Sans cela la
propriété démontrée n'est pas hyper convaincante. J'encourage les auteurs à développer cet aspect esquissé page
17 (avant la section 4).\\
\textcolor{blue}{La phrase ``Ce cas est donc très improbable.'' (en parlant d'un classifieur qui renverrait un vecteur de récompense $\theta_C=0$) a été changée pour : ``Des mécanismes de régularisation dépendant du classifieur choisi peuvent être employés pour éviter cela.''. La normalisation mentionnée immédiatement après ne l'est que pour désamorcer les interrogations du lecteur quant à la présence dans la borne du terme $||\R_{\theta_c}||_\infty$. Le sujet de la régularisation de la récompense dans le cadre de l'IRL est assez subtil (du fait de la relation complexe entre récompense et valeur) et mérite un papier à part entière. Nous n'avons pas introduit ici les outils qui nous permettraient de mener cette discussion.}
\item Une troisième limitation est que je souhaiterais être convaincu de la pertinence de l'ARI. L'application à la conduite automobile est sympathique, mais que fait-on des résultats obtenus ?\\
  \textcolor{blue}{La première phrase de l'introduction a été augmentée afin de pointer plus finement vers la référence historique de l'ARI ainsi qu'une référence récente, qui expliquent l'intérêt de l'approche mieux que nous n'avons la place de le faire : ``historiquement proposée dans (Russell, 1998),
ce mécanisme trouve des applications dans divers champs, de la biologie à la neuropsychologie en passant par l’économie et plus récemment la robotique (Abbeel et al., 2010)''.}
\item Regrettons l'absence d'un état de l'art des résultats de complexité (même succinct) pour justifier le fait que l'estimation de valeur de police est plus facile que l'apprentissage par renforcement. \\
  \textcolor{blue}{Dans la section 5 (comparaison à l'existant), la note de bas de page suivante a été ajoutée : ``La résolution d'un MDP (en utilisant par exemple un algorithme d'\emph{itération de la valeur}) implique en effet de calculer de manière répétée la valeur d'une politique arbitraire. Résoudre plusieurs fois le MDP pour des récompenses arbitraires est donc beaucoup plus dur que d'estimer une fois pour toutes l'attribut moyen de l'expert.''}
\end{itemize}\vspace{1.5 em}
  \textcolor{blue}{Les typos relevées ont été corrigées.}
\vspace{.5cm}
\newpage
\begin{large} \textbf{Reviewer 3:} \\ \end{large}
\begin{itemize}
\item Alg. 1 pas clair.
\textcolor{blue}{Nous avons rajouté le nom de la fonction de score dans l'algorithme :  $s_\theta(s,a) = \theta^\top\hat{\mu}^{\pi_E}(s,a)$. Mais nous ne sommes pas sûrs que cela améliore vraiment les choses. Il semble difficile de rendre l'algorithme plus clair que ce qu'il est déjà.}
\item Les auteurs ont mégoté sur les définitions, ce qui n'est jamais bon signe; définir $\pi_1..\pi_t$.Je suppose qu'il s'agit des actions choisies aux t premiers pas de temps.
Donner l'intuition de c(t); clarifier ce qui se passe si la distribution stationnaire ne passe pas en s\\
\textcolor{blue}{Les définitions sont présentes dans le papier de Munos. Les contraintes de place et de clarté ne nous permettent pas de reprendre toute l'explication développée par celui-ci. Comme la présence des $\pi_1 etc.$ sous le signe $\max$ le laisse entendre, il s'agit de variables muettes, il peut s'agir de n'importe quelle série de politiques. La discussion sur la signification des coefficients de concentrations est présente dans le papier cité, il apparaît délicat de la paraphraser ici sans alourdir la lecture.}
\item Lemme 4.2 de Munos n'est pas ça du tout (version Hal).\\
\textcolor{blue}{Pour respecter les contraintes de places, il est attendu du lecteur qu'il fasse le développement suivant afin de justifier l'inégalité (b) :
\begin{eqnarray}
  v^{*} - v^{\pi_E} \leq \gamma P_{\pi^*}(v^*-v^{\pi_E}) + T^*
    v^{\pi_E} - v^{\pi_E}\\
    v^{*} - v^{\pi_E} - \gamma P_{\pi^*}(v^*-v^{\pi_E}) \leq T^*
    v^{\pi_E} - v^{\pi_E}\\
    (I- \gamma P_{\pi^*})(v^*-v^{\pi_E}) \leq T^*
    v^{\pi_E} - v^{\pi_E}\\
    v^*-v^{\pi_E} \leq (I- \gamma P_{\pi^*}) ^{-1}(T^*
    v^{\pi_E} - v^{\pi_E})
 \end{eqnarray}
(1) est donné par l'inégalité (a) de notre contribution, le passage de (3) à (4) se fait grâce au Lemme 4.2 du papier de Munos (dans sa version HAL).
}
\item En pratique il est satisfaisant ... p. 17. non; à la rigueur, il est suffisant...\\
  \textcolor{blue}{Changement effectué.}
\item L'erreur sur la projection des états ds l'espace des attributs moyens ; ce paragraphe pourrait être affiné en considérant la marge du cmc sous-jacent.\\
  \textcolor{blue}{Nous perdrions alors en généralité, nous considérons aussi les cmc sans marges.}
\item 4.1.
le modèle; préciser.\\
 \textcolor{blue}{ ``Le modèle ...'' devient ``Le modèle (les probabilités de transition $P$) ...''.}
 \item ligne suivante, charabia.\\
 \textcolor{blue}{ ``Soit $\Phi\in R^{|S|\times p}$ la matrice d'attributs donc les lignes contiennent les vecteurs d'attributs $\phi(s)^T$, pour tout $s\in S$.'' devient ``Soit $\Phi\in R^{|S|\times p}$ la matrice d'attributs dont les lignes sont indexées par $s\in S$ et contiennent les vecteurs d'attributs $\phi(s)^T$''.}
 \item Discuter le rapport entre gamma et la longueur N des trajectoires disponibles.\\
 \textcolor{blue}{Il n'y a pas de rapport. Nous avons pris $\gamma = 0.9$ comme le veut la coutume. Une étude superficielle (comprendre, on a joué avec sur quelques runs) ne montre pas de sensibilité évidente de l'algorithme à ce paramètre. Une étude systématique n'a pas été entreprise et ne nous semble pas extrêmement pertinente.}
\item Si on a une bonne description psi des états, pourquoi a-t-on besoin des $\mu$ ?
\textcolor{blue}{Car $\mu$ contient de l'information quant à la dynamique engendrée par la politique de l'expert.}
\item
  omettre note 1 ou ajouter des détails.
notations 2.3 $\psi(s,a)= (psi1(s,a),...)$
d'autres choix sont possibles:non. dire lesquels ou omettre la phrase.
dacile, estumation, p. 16
recontres
\textcolor{blue}{Corrections effectuées telles que suggérées.
}
\end{itemize}

\newpage

\color{blue} Encore une fois, nous remercions les reviewers et les éditeurs pour le temps passé à nous aider à améliorer notre contribution.

Cordialement,

\begin{flushright}
Edouard Klein, Matthieu Geist, \\ Bilal Piot, Olivier Pietquin.
\end{flushright}

%\closing{Best regards,}

\end{letter}
\end{document}
