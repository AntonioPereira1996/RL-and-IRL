{
 "metadata": {
  "name": "Exp13"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#CSI on the Highway\n",
      "from DP import *\n",
      "from stuff import *\n",
      "from pylab import *\n",
      "from random import *\n",
      "import numpy\n",
      "from rl import *\n",
      "P = genfromtxt(\"Highway_P.mat\")\n",
      "R = genfromtxt(\"Highway_R.mat\")\n",
      "Gamma = 0.9\n",
      "ACTION_SPACE = range(0,5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Highway = MDP(P,R)\n",
      "mPi_E, V_E, Pi_E = Highway.optimal_policy()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "MDP OK3\n",
        "Shape of P (3645, 729)\n",
        "Shape of R (3645,)\n",
        "Card of S 729\n",
        "Card of A 5\n",
        "Card of SA 3645\n",
        "Iteration 0, 729\tactions changed."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 0, 578\tactions changed."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 0, 746\tactions changed."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 0, 384\tactions changed."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 0, 192\tactions changed."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 0, 24\tactions changed."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iteration 0, 0\tactions changed."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rho = lambda : int(rand()*729) #uniform distribtion over S\n",
      "D_E = array(Highway.D_func(Pi_E, 1, 100,  rho))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Classification\n",
      "#Structured Classifier\n",
      "class GradientDescent(object):\n",
      "   def alpha( self, t ):\n",
      "      raise NotImplementedError, \"Cannot call abstract method\"\n",
      "\n",
      "   theta_0=None\n",
      "   Threshold=None\n",
      "   T = -1\n",
      "   sign = None\n",
      "        \n",
      "   def run( self, f_grad, f_proj=None, b_norm=False ): #grad is a function of theta\n",
      "      theta = self.theta_0.copy()\n",
      "      best_theta = theta.copy()\n",
      "      best_norm = float(\"inf\")\n",
      "      best_iter = 0\n",
      "      t=0\n",
      "      while True:#Do...while loop\n",
      "         t+=1\n",
      "         DeltaTheta = f_grad( theta )\n",
      "         current_norm = norm( DeltaTheta )\n",
      "         if b_norm and  current_norm > 0.:\n",
      "             DeltaTheta /= norm( DeltaTheta )\n",
      "         theta = theta + self.sign * self.alpha( t )*DeltaTheta\n",
      "         if f_proj:\n",
      "             theta = f_proj( theta )\n",
      "         print \"Norme du gradient : \"+str(current_norm)+\", pas : \"+str(self.alpha(t))+\", iteration : \"+str(t)\n",
      "\n",
      "         if current_norm < best_norm:\n",
      "             best_norm = current_norm\n",
      "             best_theta = theta.copy()\n",
      "             best_iter = t\n",
      "         if current_norm < self.Threshold or (self.T != -1 and t >= self.T):\n",
      "             break\n",
      "\n",
      "      print \"Gradient de norme : \"+str(best_norm)+\", a l'iteration : \"+str(best_iter)\n",
      "      return best_theta\n",
      "\n",
      "\n",
      "class StructuredClassifier(GradientDescent):\n",
      "    sign=-1.\n",
      "    Threshold=0.1 #Sensible default\n",
      "    T=100 #Sensible default\n",
      "    phi=None\n",
      "    label_set=None\n",
      "    \n",
      "    def alpha(self, t):\n",
      "        return 3./(t+1)#Sensible default\n",
      "    \n",
      "    def __init__(self, psi, actions, nb_actions):\n",
      "        self.label_set=range(0,nb_actions)\n",
      "        self.N,self.K = psi.shape\n",
      "        self.A = nb_actions\n",
      "        self.theta_0 = zeros(self.K*self.A)\n",
      "        self.ExpertDecision = zeros((self.N,self.A))\n",
      "        for i,j in zip( range(0,self.N), actions.reshape(self.N) ):\n",
      "            self.ExpertDecision[i,j] = 1.\n",
      "        self.Structure = array(self.ExpertDecision!=1)\n",
      "        self.ExpertDecision = self.ExpertDecision.reshape(self.N,self.A,1)\n",
      "        self.Psi_3 = array([[p for i in range(0,self.A)] for p in psi])\n",
      "        self.Phi = self.ExpertDecision*self.Psi_3\n",
      "        self.Phi = self.Phi.reshape(self.N,self.K*self.A)\n",
      "        self.Psi = psi\n",
      "    \n",
      "    def gradient(self, theta):\n",
      "        theta_2 = hstack([theta[i*self.K:(i+1)*self.K].reshape((self.K,1)) for i in range(0,self.A)])\n",
      "        score = dot(self.Psi,theta_2)+self.Structure\n",
      "        maxScore = dot(score.max(axis=1).reshape((self.N,1)),ones((1,self.A)))\n",
      "        decision = (score==maxScore).reshape(self.N,self.A,1)\n",
      "        #We restrict ourselves to one arbitrary decision\n",
      "        for i in range(0,self.N):\n",
      "            gotOne = False\n",
      "            for j in range(0,self.A):\n",
      "                if decision[i,j] and not gotOne:\n",
      "                    gotOne = True\n",
      "                elif decision[i,j] and gotOne:\n",
      "                    decision[i,j] = False\n",
      "        phi_star = decision*self.Psi_3\n",
      "        phi_star = phi_star.reshape(self.N,self.K*self.A)\n",
      "        return mean(phi_star-self.Phi,axis=0)\n",
      "    \n",
      "    def run(self):\n",
      "        f_grad = lambda theta: self.gradient(theta)\n",
      "        theta = super(StructuredClassifier,self).run( f_grad, b_norm=True)\n",
      "        return theta\n",
      "    \n",
      "Psi = zeros((len(D_E),729))\n",
      "for i,j in zip(range(0,len(D_E)),D_E[:,0]):\n",
      "    Psi[i,j]=1.\n",
      "clf = StructuredClassifier(Psi, D_E[:,1], 5)\n",
      "theta_C = clf.run()\n",
      "def single_phi(sa):\n",
      "    answer = zeros((3645,1))\n",
      "    answer[sa[0] + 729*sa[1]] = 1.\n",
      "    return answer\n",
      "phi = non_scalar_vectorize(single_phi, (2,), (3645,1))\n",
      "q = lambda sa: squeeze(dot(theta_C.transpose(),phi(sa)))\n",
      "pi_c = greedy_policy(theta_C,phi,ACTION_SPACE, s_dim=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Norme du gradient : 0.324345494805, pas : 1.5, iteration : 1\n",
        "Norme du gradient : 0.324345494805, pas : 1.0, iteration : 2\n",
        "Norme du gradient : 0.324345494805, pas : 0.75, iteration : 3\n",
        "Norme du gradient : 0.324345494805, pas : 0.6, iteration : 4\n",
        "Norme du gradient : 0.324345494805, pas : 0.5, iteration : 5\n",
        "Norme du gradient : 0.215406592285, pas : 0.428571428571, iteration : 6\n",
        "Norme du gradient : 0.132664991614, pas : 0.375, iteration : 7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.132664991614, pas : 0.333333333333, iteration : 8\n",
        "Norme du gradient : 0.12, pas : 0.3, iteration : 9\n",
        "Norme du gradient : 0.12, pas : 0.272727272727, iteration : 10"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norme du gradient : 0.12, pas : 0.25, iteration : 11\n",
        "Norme du gradient : 0.06, pas : 0.230769230769, iteration : 12"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Gradient de norme : 0.06, a l'iteration : 12\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Donn\u00e9es pour la regression\n",
      "column_shape = (len(D_E),1)\n",
      "s = D_E[:,0].reshape(column_shape)\n",
      "a = D_E[:,1].reshape(column_shape)\n",
      "sa = D_E[:,:2]\n",
      "s_dash = D_E[:,3].reshape(column_shape)\n",
      "a_dash = pi_c(s_dash).reshape(column_shape)\n",
      "sa_dash = hstack([s_dash,a_dash])\n",
      "hat_r = (q(sa)-Gamma*q(sa_dash)).reshape(column_shape)\n",
      "r_min = min(hat_r)-1.*ones(column_shape)\n",
      "\n",
      "##Avec l'heuristique : \n",
      "regression_input_matrices = [hstack([s,action*ones(column_shape)]) for action in ACTION_SPACE] \n",
      "def add_output_column( reg_mat ):\n",
      "    actions = reg_mat[:,-1].reshape(column_shape)\n",
      "    hat_r_bool_table = array(actions==a)\n",
      "    r_min_bool_table = array(hat_r_bool_table==False) #\"not hat_r_bool_table\" does not work as I expected\n",
      "    output_column = hat_r_bool_table*hat_r+r_min_bool_table*r_min\n",
      "    return hstack([reg_mat,output_column])\n",
      "regression_matrix = vstack(map(add_output_column,regression_input_matrices))\n",
      "#R\u00e9gression\n",
      "from sklearn.svm import SVR\n",
      "y = regression_matrix[:,-1]\n",
      "X = regression_matrix[:,:-1]\n",
      "reg = SVR(C=1.0, epsilon=0.2)#, gamma=1/(2*pow(0.03,2)))\n",
      "reg.fit(X, y)\n",
      "fCSI_reward = lambda sa:reg.predict(sa)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named sklearn.svm",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-6-a057a9fd0008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mregression_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_output_column\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregression_input_matrices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#R\ufffd\ufffdgression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregression_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregression_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mImportError\u001b[0m: No module named sklearn.svm"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Sgenerator( ):\n",
      "    for v in range(0,3):\n",
      "        for x_b in range(0,9):\n",
      "            for y_r in range(0,9):\n",
      "                for x_r in range(0,3):\n",
      "                    yield [v,x_b,y_r,x_r]\n",
      "\n",
      "S = [s for s in Sgenerator()]\n",
      "\n",
      "A = range(0,5)\n",
      "\n",
      "def s_index( state ):\n",
      "    v = state[0]\n",
      "    x_b = state[1]\n",
      "    y_r = state[2]\n",
      "    x_r = state[3]\n",
      "    index = x_r + y_r*3 + x_b*3*9 + v*3*9*9\n",
      "    return index\n",
      "\n",
      "def sa_index( state, action ):\n",
      "    index = s_index(state) + a*3*9*9*3\n",
      "    return index\n",
      "\n",
      "reward_CSI=zeros((3645,1))\n",
      "for state in S:\n",
      "    for action in ACTION_SPACE:\n",
      "        index = sa_index(state, action)\n",
      "        reward_CSI[index] = fCSI_reward(array([state,action]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Highway2 = MDP(P,reward_CSI)\n",
      "mPi_A, V_A, Pi_A = Highway2.optimal_policy()\n",
      "true_V_A = linalg.solve( identity( 729 ) - 0.9*dot(mPi_A,P), dot( mPi_A, R) )\n",
      "Highway3 = MDP(P,rand(3645,1))\n",
      "mPi_R, V_R, Pi_R = Highway3.optimal_policy()\n",
      "true_V_R = linalg.solve( identity( 729 ) - 0.9*dot(mPi_R,P), dot( mPi_R, R) )\n",
      "mean(true_V_A),mean(true_V_R),mean(V_E)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}