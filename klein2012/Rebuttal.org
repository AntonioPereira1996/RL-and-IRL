We would like to insist that our algorithm does not perform "about as well as PIRL in terms of sample complexity" as stated by reviewer 3 but is able to work where PIRL fails. Indeed, it is very important to note that PIRL was fed with the transition probabilities and the full policy of the expert whereas SCIRL had to work only on transitions from the expert. PIRL could not converge when only given transitions from the expert, as these transitions bear not enough information to solve the Reinforcement Learning problem (which PIRL uses as a subroutine, and SCIRL does not need).
What we empirically show is that SCIRL gives results on par with PIRL, but needing far less information.

As for the computation time, we did not advertise this feature as very important, hence the lack of rigor about the results. A quick and dirty mixed theoretical and empirical analysis goes like this :
Solving the forward RL problem knowing the transition probabilities is akin to inversing a NxN matrix, where N is the cardinal of the state space. This is worse than O(N^2). The intermediate computations of PIRL are easier than that, so this gives PIRL a runnning time of more than O(N^2) per iteration.
SCIRL is a subgradient descent algorithm, the subgradient being computed by the sum (over the samples) of a matrix product. Say we have M samples and a feature space of dimension P. We have 0<M<N and 0<P<=N. We have less samples than there is space in the state space, as the whole point of our algorithm os to work in the difficult case where samples are few and states are many. We also have less or as much features as states. The latter case is the cas of tabular, exact representation of the reward function. So each iteration of SCIRL is in O(M*P) < O(N^2).
Add to that the computation of \mu_E (which is done once and for all at the start of the SCIRL algorithm) that, as a policy evaluation problem, is necessarily faster than a full fledged RL resolution : Via a monte-carlo method in can be done in less than O(M^2).
Empirically, we stopped PIRL after at most 40 iterations, and would let SCIRL run for as much as 400 iterations although far less were necessary. This gives a runnung time for PIRL of more than 40*O(N^2) and for SCIRL of less than O(M^2)+400*O(M*P). With P=N=~1000 and M\in [1,400] as that was the case on the highway driving simulator, it is clear that SCIRL is much faster than PIRL.
 
