* Génération des données d'entrainement

  Grâce au pipeline d'entrainement

  #+begin_src makefile :tangle Makefile
NBTRAININGEP=10

all:
	if [ -f TrainingSA-1.mat ]; then rm TrainingSA-*.mat; fi
	for i in `seq 1 $(NBTRAININGEP)`; do ./TrainingPipeline.py >> TrainingSA-$$i.mat; done
  #+end_src

  On passe du format s,a à s,a,s',r,eoe attendu par le code de SCIRL
  #+begin_src makefile :tangle Makefile
	./sa2sasreoe.py $(NBTRAININGEP)
  #+end_src
  

* Exécution de SCIRL sur ces données 
  #+begin_src makefile :tangle Makefile
	./SCIRL.py TrainingSASREOE.mat
  #+end_src
  
* Optimisation de la récompense en une politique
   LSPI a besoin de samples couvrant tout l'espace d'état
  #+begin_src makefile :tangle Makefile
	./RandomPipeline.py > RandomSamples.mat
	 gcc -I.. --std=c99 `pkg-config --cflags gsl` ourLSPI.c -c
	 gcc `pkg-config --libs gsl` ../LSPI.o ../LSTDQ.o ../greedy.o ourLSPI.o ../utils.o -o ourLSPI.exe
	./ourLSPI.exe theta_scirl.mat > omega_expert.mat
  #+end_src
* Test de la politique
  #+begin_src makefile :tangle Makefile
	for i in `seq 1 10`; do ./TestingPipeline.py ; done
  #+end_src

* Cleaning rule
  #+begin_src makefile :tangle Makefile
clean:
	rm omega_expert.mat *.pyc RandomSamples.mat theta_scirl.mat Training*.mat 
  #+end_src
